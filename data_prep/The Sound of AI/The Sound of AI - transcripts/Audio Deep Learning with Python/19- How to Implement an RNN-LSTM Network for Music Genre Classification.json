{
    "jobName": "transcript-job-audio-assistant",
    "accountId": "337909742319",
    "status": "COMPLETED",
    "results": {
        "transcripts": [
            {
                "transcript": "Hi, everybody and welcome to the last video in the Deep Learning for Rode with Python series. This time we're gonna implement an RNNLSDM network for music genre classification. Now we've already built a convolutional neural network that can do, can perform a music genre classification. So we're basically gonna use that code as a basis and we're gonna just change a few things around that makes sense. So to have an RNNLSDM instead of a CNN, right? OK. So uh let's see like what the code that we already have and we'll start from the main and if you guys like have followed along in the series, you probably can recognize most of this code because we've already done this like in previous videos. So over here, uh the first thing that we'll do is we'll get a train validation and splits starting from the MF CCS that we've extracted in a previous video where we pre processed a data, data set for um the, the for the music genre classification task, right? So once we have this data set, so uh for train validation and test. So what what we do next is we create the network and uh When we create the network over here, we have this build a model function that we need to change for obvious reasons. Because build model in this code is gonna build a CNN and we want to convert that to an RNN, then we compile the model, then we get like a summary of the model. Then we train the model with model dot fits. Uh Then we want to plot the accuracy and error for training and validation. And we have this function here that does that. And finally, we want to evaluate the model on, on the test set to see how well it does and how capable it is to generalize. OK. So let's get started and see like what we need to change here. So the first thing is this prepare a data sets and here we have a couple of arguments that we pass. So no 0.25 in this case indicates that we use 1/4 of the data set for testing purposes. And this no 0.2 over here says that of the remaining 75% we want to use 20% of that for the validation split. Cool. But what should we change here? Well, let's go and figure that out. So here in prepared data sets, uh we just like load uh the data and then obviously we load both the inputs and uh the the targets, what the whys and then we create train validation and test split. And he here, once we have that uh for CNN, we had to add an extra access to the input sets. And you have it here, for example. So X strain is equal to X strain with this like weird like three dots comma NPNP dot New access. So we are adding a third dimension and this is because in a CNN tensorflow expects three dimensions. And in this case, the first one, the first dimension represents the number of steps that we have. So the number of uh MFCC slices that we take. The second dimension is 13 in this case, which is the number of MF CCS that we are actually taking at each snapshot. And the third dimension is equal to the depth and the depth with any audio data is usually just one because we have like only one dimension go so to prepare the data set for an R and N, we don't need this third dimension. So we'll just drop that. And so with that, we should have done all that's required for prepared data sets. So now let's go back to domain over here. So now uh after uh like this uh line of instruction, so we should have the train validation and test splits. And now we should create the network. Now we should change another thing here. So it's the input shape. So the input shape. So the shape that the RNN expects in these cases, we already said that is by dimensions, it's two dimensional. So, but if you see here, uh like in this line, you see that we have like an input shape that's equal, it's a three dimensional, right? And we want to drop this third dimension over here. So which is like the depth and we remain only with two dimensions. And specifically, I believe that the first dimension is equal to 100 and 30 which is the number of slices or time steps at which we take uh the MF CCS. And then the second dimension is equal to 13, which is the actual coefficients that we extract from or we've extracted when pre when processing the data, right? And then we build the model perfect. Now we, we need to like take a look at this because this is the, the core uh of like the stuff that we have to change over here. So this is the function that generates a CNN model. Obviously, we don't want a CNN model here. Rather we want a, an R and N uh LSDM uh model. And so I'm gonna change that also here. Cool. OK. So let's see the network topology over here. So we have like we, we just like build uh this like sequential model and then we have a bunch of convolutional layers. And obviously, we want to drop all of these convolutional layers and we'll just leave the output layer over here uh which is a soft max layer with 10 neurons and this 10 neurons correspond with the 10 different genres that we want to predict. Good. OK. So uh what we need to build here is a couple of uh LSDM layers. So we'll build two LSTM uh layers, right? OK. So how do we do that? Well, that is as usual with uh sensor flu and carers. Very, very simple. So we do a model dot art and then we want to add analys TM layer uh and to do that, not surprisingly, we do Kous dot Layers dot LSTM good. OK. So here we should specify a few things. So the first one is the number of units that we want for this LSTM layer and this is equal to 64. So we're gonna have 64 units. Then we need to specify the input shape and the input shape is gonna be equal to input shape, which is this um uh argument that we are passing to build model to, to this function. And then we need a, an extra um an extra argument here which is really like a, a boolean argument that's called a return sequences and we need to set this to true. So what is this? Well, if you guys remember from my video on R and MS and if you haven't watched that, you should go like uh uh and watch that out because like it will give you like a more profound understanding of what we are doing here. But if you remember that we have two types of RNM uh layers. So one is called sequence to sequence. And so basically, we pass in a sequence to an RNN layer and then we get back a, a sequence. Uh And there's another one that's called a sequence to vector. So we pass in as input as sequence. Uh So for example, a time series, but then we don't get a sequence as an output but just like the final step. So the final prediction, it's as if like in a in a melody, I pass, I pass like 10 notes and then I expect only like the the new notes like the prediction for the 11th notes, right? OK. So here we want to return a sequence because we want a sequence to sequence uh layer and so we have to set written sequences to true. Now why do, why do we do that well? Because we want to pass that sequence into the second LSDM layer. And so the second LSDM layer uh is gonna be equal to Model dot art. And then we pass in KIS uh layers LSDM. And now all we need to pass in is the number of units which again, I'm gonna set to 64 good. So now we have two LSDM layers. So now I'm gonna have another layer that's a dense layer. So in in order to do that, so I'll do a Model dot Art again, So I hope that by now, you you just like are able just like to predict all of these instructions because I mean, we've seen them quite a lot so far and then they are very, very intuitive. And this is like the great thing about carers. So it makes things and building like this network also very complex network, quite easy to do. So again, we want to dance layers, so we'll do a Kous dot Layers dot uh dance, right? And so here we need to pass in a couple of arguments. So the first one being the number of units which we set to 64 again, and then we need to specify the activation function that we wanna use. And in this case, I'm gonna use recti rectified linear unit or R good. And I want to add also another layer that's a drop out layer. And uh I'm gonna add this just like to, to avoid uh overfitting or just like to mitigate uh the issue of overfitting. Now, if you don't remember what dropout is, again, I have a video on that uh on overfitting and how to solve that. And you should check that out and it should be like above. And so just like click that cool. OK. So uh so we were saying we want this drop out layer. So we'll do Kous dot uh again, layers dot uh drop out and then we'll set the dropout probability to uh no 0.3 or 30% good. So now I believe that we have built the whole model, the whole R and N long shot and memory network good. So just like let's revise this like very quickly. So first of all, we build, we get like this, we create this sequential model. Then we add a couple of LSDM layers. The first which is a sequence to sequence um a layer. The second one is just a sequence to vector. And I don't need to specify that because the default is return sequences equal to fault in carers. And then I've added a dense layer. And finally, uh the dense layer uh gets input into like the output layer which is a soft max classifier with 10 neurons. And uh the 10 neurons represent like the 10 different musical genres that we want to predict. Cool. So now let's go back to the um main. And so, and we'll see that all the rest over here should be fine and good to go. So we are here. So we've just like created uh the, the network, we've built the model, then we're gonna compile the model and for compiling the model, we're gonna just use like this very same setting. So I'm gonna use AAM as the optimizer with the learning rate on 0.0001. And then we'll compile uh the model and which we, we'll use like as the error function this past category called Kenty and as the metrics, we're gonna track accuracy. Uh I'll just like uh run the script here and uh see how that, how that goes. Cool. OK. So as usually it's gonna take like some time to like train the whole thing. So I'm just gonna post the video now and uh just like get back like once we have uh the results. So the training process has finished and we got the results here and the test accuracy is 64% which is a quite decent result given we have 10 different um genres. And yeah, and I think like it's probably close to the result that we also got with the CNN. Good. So yeah, I guess like this is like it for this video now, you know how to build an RNN long short term memory network, which is great. Cool. So at the same time, this is the end of the deep learning for audio with Python series. And by now if you followed it, you should be able to like build your own models and carers, be able to uh process all your data extract MF CS, perform fourier transforms and do like a bunch more things and have an understanding like of all your data more in general. Cool. I hope you really enjoyed this uh series for me. It's been like a very, very nice uh journey and if that's the case, please consider subscribing. And yeah, so uh another thing that uh would be great is if you could just le leave a comment in the comment section below and let me know what you'd like to learn next in the A I music A I audio space. That's all for today. So I hope you enjoyed all of this and if that's the case, I'll see you next time. Cheers."
            }
        ],
        "audio_segments": [
            {
                "id": 0,
                "transcript": "Hi, everybody and welcome to the last video in the Deep Learning for Rode with Python series. This time we're gonna implement an RNNLSDM network for music genre classification.",
                "start_time": "0.31",
                "end_time": "12.409"
            },
            {
                "id": 1,
                "transcript": "Now we've already built a convolutional neural network that can do, can perform a music genre classification. So we're basically gonna use that code as a basis and we're gonna just change a few things around that makes sense. So to have an RNNLSDM instead of a CNN, right? OK. So uh let's see like what the code that we already have and we'll start from the main",
                "start_time": "12.739",
                "end_time": "41.509"
            },
            {
                "id": 2,
                "transcript": "and if you guys like have followed along in the series, you probably can recognize most of this code because we've already done this like in previous videos. So over here, uh the first thing that we'll do is we'll get a train validation and",
                "start_time": "41.79",
                "end_time": "57.564"
            },
            {
                "id": 3,
                "transcript": "splits starting from the MF CCS that we've extracted in a previous video where we pre processed a data, data set for um the, the for the music genre classification task, right? So once we have this data set, so uh for train validation and test. So what what we do next is we create the network",
                "start_time": "57.575",
                "end_time": "83.739"
            },
            {
                "id": 4,
                "transcript": "and uh When we create the network over here, we have this build a model function that we need to change for obvious reasons. Because build model in this code is gonna build a CNN and we want to convert that to an RNN, then we compile the model, then we get like a summary of the model. Then we train the model with model dot fits. Uh Then we want to plot the accuracy and error for training and validation.",
                "start_time": "83.98",
                "end_time": "113.48"
            },
            {
                "id": 5,
                "transcript": "And we have this function here that does that. And finally, we want to evaluate the model on, on the test set to see how well it does and how capable it is to generalize. OK. So let's get started and see like what we need to change here. So the first thing is this prepare a data sets and here we have a couple of arguments that we pass. So no 0.25 in this case indicates that we use 1/4 of the data",
                "start_time": "113.62",
                "end_time": "142.33"
            },
            {
                "id": 6,
                "transcript": "set for testing purposes. And this no 0.2 over here says that of the remaining 75% we want to use 20% of that for the validation split. Cool. But what should we change here? Well, let's go and figure that out.",
                "start_time": "142.339",
                "end_time": "159.46"
            },
            {
                "id": 7,
                "transcript": "So here in prepared data sets, uh we just like load uh the data and then obviously we load both the inputs and uh the the targets, what the whys and then we create train validation and test split. And he",
                "start_time": "159.649",
                "end_time": "177.304"
            },
            {
                "id": 8,
                "transcript": "here, once we have that uh for CNN, we had to add an extra access to the input sets. And you have it here, for example. So X strain is equal to X strain with this like weird like three dots comma",
                "start_time": "177.315",
                "end_time": "194.979"
            },
            {
                "id": 9,
                "transcript": "NPNP dot New access. So we are adding a third dimension and this is because in a CNN tensorflow expects three dimensions. And in this case, the first one, the first dimension represents the number of steps that we have.",
                "start_time": "195.119",
                "end_time": "209.0"
            },
            {
                "id": 10,
                "transcript": "So the number of uh MFCC slices that we take. The second dimension is 13 in this case, which is the number of MF CCS that we are actually taking at each snapshot. And the third dimension is equal to the depth and the depth with any audio data is usually just one because we have like only one dimension go",
                "start_time": "209.169",
                "end_time": "232.389"
            },
            {
                "id": 11,
                "transcript": "so to prepare the data set for an R and N, we don't need this third dimension. So we'll just drop that. And so with that, we should have done all that's required for prepared data sets. So now let's go back to",
                "start_time": "232.57",
                "end_time": "248.125"
            },
            {
                "id": 12,
                "transcript": "domain over here. So now uh after uh like this uh line of instruction, so we should have the train validation and test splits. And now we should create the network. Now we should change another thing here. So it's the input shape. So the input shape. So the shape that the RNN expects in these cases, we already said that is by dimensions, it's two dimensional. So, but if you see here,",
                "start_time": "248.134",
                "end_time": "275.459"
            },
            {
                "id": 13,
                "transcript": "uh like in this line, you see that we have like an input shape that's equal, it's a three dimensional, right? And we want to drop this third dimension over here. So which is like the depth and we remain only with two dimensions. And specifically, I believe that the first dimension is equal to 100 and 30 which is the number of slices or time steps",
                "start_time": "275.7",
                "end_time": "297.779"
            },
            {
                "id": 14,
                "transcript": "at which we take uh the MF CCS. And then the second dimension is equal to 13, which is the actual coefficients that we extract from or we've extracted when pre when processing the data, right?",
                "start_time": "297.929",
                "end_time": "311.549"
            },
            {
                "id": 15,
                "transcript": "And then we build the model perfect. Now we, we need to like take a look at this because this is the, the core uh of like the stuff that we have to change over here. So this is the function that generates a CNN model. Obviously, we don't want a CNN model here. Rather we want a, an R and N uh LSDM uh model. And so I'm gonna change that also here.",
                "start_time": "311.72",
                "end_time": "339.0"
            },
            {
                "id": 16,
                "transcript": "Cool. OK. So let's see the network topology over here. So we have like we, we just like build uh this like sequential model and then we have a bunch of convolutional layers. And obviously, we want to drop all of these convolutional layers and we'll just leave the output layer over here uh which is a soft max layer with 10 neurons and this 10 neurons correspond with the 10 different genres that we want to predict.",
                "start_time": "339.66",
                "end_time": "368.85"
            },
            {
                "id": 17,
                "transcript": "Good. OK. So uh what we need to build here is a couple of uh LSDM layers. So we'll build two LSTM uh layers, right? OK. So how do we do that? Well, that is as usual with uh sensor flu and carers. Very, very simple. So we do a model dot art and then we want to add analys TM layer",
                "start_time": "369.809",
                "end_time": "398.01"
            },
            {
                "id": 18,
                "transcript": "uh and to do that, not surprisingly, we do Kous dot Layers dot LSTM good. OK. So here we should specify a few things. So the first one is the number of units that we want for this LSTM layer and this is equal to 64. So we're gonna have 64 units. Then we need to specify the input shape and the input shape is gonna be equal to input shape, which is this",
                "start_time": "398.47",
                "end_time": "427.54"
            },
            {
                "id": 19,
                "transcript": "um uh argument that we are passing to build model to, to this function. And then we need a, an extra um",
                "start_time": "427.929",
                "end_time": "437.579"
            },
            {
                "id": 20,
                "transcript": "an extra argument here which is really like a, a boolean argument that's called a return sequences and we need to set this to true. So what is this? Well, if you guys remember from my video on R and MS and if you haven't watched that, you should go like uh uh and watch that out because like it will give you like a more profound understanding of what we are doing here.",
                "start_time": "438.17",
                "end_time": "463.529"
            },
            {
                "id": 21,
                "transcript": "But if you remember that we have two types of RNM uh layers. So one is called sequence to sequence. And so basically, we pass in a sequence to an RNN layer and then we get back a, a sequence. Uh And there's another one that's called a sequence to vector. So we pass in as input as sequence.",
                "start_time": "463.69",
                "end_time": "483.92"
            },
            {
                "id": 22,
                "transcript": "Uh So for example, a time series, but then we don't get a sequence as an output but just like the final step. So the final prediction, it's as if like in a in a melody, I pass, I pass like 10 notes and then I expect only like the the new notes like the prediction for the 11th notes, right? OK. So here we want to return a sequence because we want a sequence to sequence uh layer",
                "start_time": "483.929",
                "end_time": "511.73"
            },
            {
                "id": 23,
                "transcript": "and so we have to set written sequences to true. Now why do, why do we do that well? Because we want to pass that sequence into the second LSDM layer. And so the second LSDM layer uh is gonna be equal to Model dot art. And then we pass in KIS uh layers LSDM.",
                "start_time": "512.0",
                "end_time": "537.57"
            },
            {
                "id": 24,
                "transcript": "And now all we need to pass in is the number of units which again, I'm gonna set to 64 good. So now we have two LSDM layers.",
                "start_time": "537.719",
                "end_time": "550.309"
            },
            {
                "id": 25,
                "transcript": "So now I'm gonna have another layer that's a dense layer. So in in order to do that, so I'll do a Model dot Art again,",
                "start_time": "550.89",
                "end_time": "563.15"
            },
            {
                "id": 26,
                "transcript": "So I hope that by now, you you just like are able just like to predict all of these instructions because I mean, we've seen them quite a lot so far and then they are very, very intuitive. And this is like the great thing about carers. So it makes things and building like this network also very complex network, quite easy to do. So again, we want to dance layers, so we'll do a Kous dot Layers dot uh dance,",
                "start_time": "563.53",
                "end_time": "590.96"
            },
            {
                "id": 27,
                "transcript": "right? And so here we need to pass in a couple of arguments. So the first one being the number of units which we set to 64 again, and then we need to specify the activation function that we wanna use. And in this case, I'm gonna use recti rectified linear unit or R good. And I want to add also another layer that's a drop out layer. And",
                "start_time": "591.099",
                "end_time": "617.21"
            },
            {
                "id": 28,
                "transcript": "uh I'm gonna add this just like to, to avoid uh overfitting or just like to mitigate uh the issue of overfitting. Now, if you don't remember what dropout is, again, I have a video on that uh on overfitting and how to solve that. And you should check that out and it should be like above. And so just like click that",
                "start_time": "617.44",
                "end_time": "639.239"
            },
            {
                "id": 29,
                "transcript": "cool. OK. So uh so we were saying we want this drop out layer. So we'll do Kous dot uh again, layers dot uh drop out and then we'll set the dropout probability to uh no 0.3 or 30% good. So now I believe that we have built the whole model, the whole R and N long shot and memory",
                "start_time": "639.64",
                "end_time": "665.099"
            },
            {
                "id": 30,
                "transcript": "network good. So just like let's revise this like very quickly. So first of all, we build, we get like this, we create this sequential model. Then we add a couple of LSDM layers. The",
                "start_time": "665.26",
                "end_time": "680.26"
            },
            {
                "id": 31,
                "transcript": "first which is a sequence to sequence um a layer. The second one is just a sequence to vector. And I don't need to specify that because the default is return sequences equal to fault in carers.",
                "start_time": "680.27",
                "end_time": "695.28"
            },
            {
                "id": 32,
                "transcript": "And then I've added a dense layer. And finally, uh the dense layer uh gets input into like the output layer which is a soft max classifier with 10 neurons. And uh the 10 neurons represent like the 10 different musical genres that we want to predict. Cool. So now let's go back to the um main.",
                "start_time": "695.59",
                "end_time": "720.76"
            },
            {
                "id": 33,
                "transcript": "And so, and we'll see that all the rest over here should be fine and good to go. So we are here. So we've just like created uh the, the network, we've built the model, then we're gonna compile the model and for compiling the model, we're gonna just use like this very same setting. So I'm gonna use AAM as the optimizer with the learning rate on 0.0001.",
                "start_time": "721.34",
                "end_time": "745.219"
            },
            {
                "id": 34,
                "transcript": "And then we'll compile uh the model and which we, we'll use like as the error function this past category called Kenty and as the metrics, we're gonna track accuracy. Uh I'll just like uh run the script here and uh see how that, how that goes. Cool. OK.",
                "start_time": "745.82",
                "end_time": "769.109"
            },
            {
                "id": 35,
                "transcript": "So as usually it's gonna take like some time to like train the whole thing. So I'm just gonna post the video now and uh just like get back like once we have uh the results. So the training process has finished and we got the results here and the test accuracy is 64% which is a quite decent result given we have 10 different um genres.",
                "start_time": "769.44",
                "end_time": "796.14"
            },
            {
                "id": 36,
                "transcript": "And yeah, and I think like it's probably close to the result that we also got with the CNN. Good. So yeah, I guess like this is like it for this video now, you know how to build an RNN long short term memory network, which is great. Cool. So at the same time, this is the end of the deep learning for audio with Python series. And by now if you followed it,",
                "start_time": "796.469",
                "end_time": "819.69"
            },
            {
                "id": 37,
                "transcript": "you should be able to like build your own models and carers, be able to uh process all your data extract MF CS, perform fourier transforms and do like a bunch more things and have an understanding like of all your data more in general.",
                "start_time": "819.7",
                "end_time": "835.729"
            },
            {
                "id": 38,
                "transcript": "Cool. I hope you really enjoyed this uh series for me. It's been like a very, very nice uh journey and if that's the case, please consider subscribing. And yeah, so uh another thing that uh would be great is if you could just le leave a comment in the comment section below and let me know what you'd like to learn next in the A I music A I audio space.",
                "start_time": "836.239",
                "end_time": "861.599"
            },
            {
                "id": 39,
                "transcript": "That's all for today. So I hope you enjoyed all of this and if that's the case, I'll see you next time. Cheers.",
                "start_time": "862.07",
                "end_time": "868.82"
            }
        ]
    }
}