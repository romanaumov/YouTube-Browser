[
    {
        "id": "6191a52c",
        "text": "Hi, everybody and welcome to a new video in the Deep learning for audio with Python series. This time we're gonna implement back propagation and gradient descent. And to do that, we're gonna expand on the work we've done uh a couple of videos ago when we implemented a multi layer perception class, this M LP objects here. And uh in that case, we built a uh constructor where basically we built like the, the structure of the network. And then we mainly uh focused on this forward propagate method uh which is basically forward propagation which computes the inputs uh which travel uh from left to right and gives us a prediction good. So what are we gonna do specifically like this time around? Well, it's a bunch of like different things and so it's better just like to write them down so that we'll have more or less like a direction that we know we're following because by the way, this is gonna be like a quite intense view and probably quite long as well good. So",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=0s",
        "start_time": "0.0"
    },
    {
        "id": "336887b1",
        "text": "And uh in that case, we built a uh constructor where basically we built like the, the structure of the network. And then we mainly uh focused on this forward propagate method uh which is basically forward propagation which computes the inputs uh which travel uh from left to right and gives us a prediction good. So what are we gonna do specifically like this time around? Well, it's a bunch of like different things and so it's better just like to write them down so that we'll have more or less like a direction that we know we're following because by the way, this is gonna be like a quite intense view and probably quite long as well good. So uh the first thing that we want to do is to save the activations and the derivatives",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=21s",
        "start_time": "21.079"
    },
    {
        "id": "79c3a411",
        "text": "So what are we gonna do specifically like this time around? Well, it's a bunch of like different things and so it's better just like to write them down so that we'll have more or less like a direction that we know we're following because by the way, this is gonna be like a quite intense view and probably quite long as well good. So uh the first thing that we want to do is to save the activations and the derivatives and derivative, right. So this is like while we to compute uh back propagation, we need information about activations and obviously about like the uh derivatives as well. When we'll compute a gradient descent, then uh what we want to do is to uh implement back propagate back propagation.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=46s",
        "start_time": "46.389"
    },
    {
        "id": "2824b2cb",
        "text": "uh the first thing that we want to do is to save the activations and the derivatives and derivative, right. So this is like while we to compute uh back propagation, we need information about activations and obviously about like the uh derivatives as well. When we'll compute a gradient descent, then uh what we want to do is to uh implement back propagate back propagation. So once we have it back propagation implemented, we want to implement a gradient",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=66s",
        "start_time": "66.37"
    },
    {
        "id": "f3c41a21",
        "text": "and derivative, right. So this is like while we to compute uh back propagation, we need information about activations and obviously about like the uh derivatives as well. When we'll compute a gradient descent, then uh what we want to do is to uh implement back propagate back propagation. So once we have it back propagation implemented, we want to implement a gradient Grady and uh descent. And once we have that it's time to go higher like from a higher level and implement a train method which will use both back propagation and gradient descent. And uh then we want to train our nets work with some dummy data set",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=77s",
        "start_time": "77.129"
    },
    {
        "id": "b74114dc",
        "text": "So once we have it back propagation implemented, we want to implement a gradient Grady and uh descent. And once we have that it's time to go higher like from a higher level and implement a train method which will use both back propagation and gradient descent. And uh then we want to train our nets work with some dummy data set and finally make some predictions",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=105s",
        "start_time": "105.11"
    },
    {
        "id": "88b99746",
        "text": "Grady and uh descent. And once we have that it's time to go higher like from a higher level and implement a train method which will use both back propagation and gradient descent. And uh then we want to train our nets work with some dummy data set and finally make some predictions good. So this is the plan for today's video. So let's get started from the first one. So save activations and derivatives, right? So first of all, uh we need uh a representations for uh data representation for these activations and derivatives. And we need to create uh this representation here in the M LP uh construct,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=111s",
        "start_time": "111.65"
    },
    {
        "id": "495e1761",
        "text": "and finally make some predictions good. So this is the plan for today's video. So let's get started from the first one. So save activations and derivatives, right? So first of all, uh we need uh a representations for uh data representation for these activations and derivatives. And we need to create uh this representation here in the M LP uh construct, right? And so as we did for the weights here where we basically created some random weights, uh We should do like a similar thing uh for the activations and derivatives. So let's get started activations and we'll start with uh an empty list. I don't like that. That is uh like that nice. And now we'll do a four loop and we'll go through all the uh layers here,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=139s",
        "start_time": "139.57"
    },
    {
        "id": "b4bf42ea",
        "text": "good. So this is the plan for today's video. So let's get started from the first one. So save activations and derivatives, right? So first of all, uh we need uh a representations for uh data representation for these activations and derivatives. And we need to create uh this representation here in the M LP uh construct, right? And so as we did for the weights here where we basically created some random weights, uh We should do like a similar thing uh for the activations and derivatives. So let's get started activations and we'll start with uh an empty list. I don't like that. That is uh like that nice. And now we'll do a four loop and we'll go through all the uh layers here, right? We'll go through all the layers and then we want to create a dummy uh activation array for each of the, of the layers. So how do we do that? So, it's quite simple. So it's uh we'll create an array A which is given by NP dot uh And we'll do zeros here. So it's all, it's an array of zeros. And we'll specify that we want",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=143s",
        "start_time": "143.289"
    },
    {
        "id": "58550a11",
        "text": "right? And so as we did for the weights here where we basically created some random weights, uh We should do like a similar thing uh for the activations and derivatives. So let's get started activations and we'll start with uh an empty list. I don't like that. That is uh like that nice. And now we'll do a four loop and we'll go through all the uh layers here, right? We'll go through all the layers and then we want to create a dummy uh activation array for each of the, of the layers. So how do we do that? So, it's quite simple. So it's uh we'll create an array A which is given by NP dot uh And we'll do zeros here. So it's all, it's an array of zeros. And we'll specify that we want uh an amount uh of zeros here. That's equal to the number of neurons that we have in uh each layer, right, for each layer. So then we'll do a activations dot append and we'll append uh this mono dimensional one dimensional array here to activations.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=164s",
        "start_time": "164.66"
    },
    {
        "id": "6b588dad",
        "text": "right? We'll go through all the layers and then we want to create a dummy uh activation array for each of the, of the layers. So how do we do that? So, it's quite simple. So it's uh we'll create an array A which is given by NP dot uh And we'll do zeros here. So it's all, it's an array of zeros. And we'll specify that we want uh an amount uh of zeros here. That's equal to the number of neurons that we have in uh each layer, right, for each layer. So then we'll do a activations dot append and we'll append uh this mono dimensional one dimensional array here to activations. So in the end activations is gonna be a list of arrays where each array in the list uh represents the activations for a given layer, right. So now we want to store all of this uh information in a instance, variable called uh activations. And so self dodge uh activations is gonna be equal to activations. Nice.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=195s",
        "start_time": "195.449"
    },
    {
        "id": "f938cac4",
        "text": "uh an amount uh of zeros here. That's equal to the number of neurons that we have in uh each layer, right, for each layer. So then we'll do a activations dot append and we'll append uh this mono dimensional one dimensional array here to activations. So in the end activations is gonna be a list of arrays where each array in the list uh represents the activations for a given layer, right. So now we want to store all of this uh information in a instance, variable called uh activations. And so self dodge uh activations is gonna be equal to activations. Nice. So now we should do something similar with derivatives as well. So I'll just copy all of this and paste it here. So instead of um activations, we'll have like derivatives here. So",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=226s",
        "start_time": "226.669"
    },
    {
        "id": "a96dd70d",
        "text": "So in the end activations is gonna be a list of arrays where each array in the list uh represents the activations for a given layer, right. So now we want to store all of this uh information in a instance, variable called uh activations. And so self dodge uh activations is gonna be equal to activations. Nice. So now we should do something similar with derivatives as well. So I'll just copy all of this and paste it here. So instead of um activations, we'll have like derivatives here. So we have this like empty list derivatives. And now we want to travel through so loop through",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=253s",
        "start_time": "253.899"
    },
    {
        "id": "c685feb9",
        "text": "So now we should do something similar with derivatives as well. So I'll just copy all of this and paste it here. So instead of um activations, we'll have like derivatives here. So we have this like empty list derivatives. And now we want to travel through so loop through the layers but all the layers like minus one. Because if you guys remember when we have, for example, a network with uh three layers, we only have two weight mattresses because the weight mattresses are in between layers, right?",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=279s",
        "start_time": "279.369"
    },
    {
        "id": "1591a8dd",
        "text": "we have this like empty list derivatives. And now we want to travel through so loop through the layers but all the layers like minus one. Because if you guys remember when we have, for example, a network with uh three layers, we only have two weight mattresses because the weight mattresses are in between layers, right? And so, uh in this case, we are gonna have a number of like derivatives or uh that are like equal to the weight mattresses, right? Because the derivatives are the derivatives of the error function with respect to the to the weight cool. So let's change this. So we'll call this D",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=295s",
        "start_time": "295.19"
    },
    {
        "id": "1347c2a9",
        "text": "the layers but all the layers like minus one. Because if you guys remember when we have, for example, a network with uh three layers, we only have two weight mattresses because the weight mattresses are in between layers, right? And so, uh in this case, we are gonna have a number of like derivatives or uh that are like equal to the weight mattresses, right? Because the derivatives are the derivatives of the error function with respect to the to the weight cool. So let's change this. So we'll call this D and now we're not expecting a mono dimensional array rather like a two dimensional array, which is basically a matrix. And uh this matrix uh is gonna have uh the, the dimensions like say for, for the rows, we expect the number of um neurons that we have in the current layer I and for the columns, we expect the number of neurons uh that we have in the subsequent layer, right?",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=302s",
        "start_time": "302.329"
    },
    {
        "id": "51105faf",
        "text": "And so, uh in this case, we are gonna have a number of like derivatives or uh that are like equal to the weight mattresses, right? Because the derivatives are the derivatives of the error function with respect to the to the weight cool. So let's change this. So we'll call this D and now we're not expecting a mono dimensional array rather like a two dimensional array, which is basically a matrix. And uh this matrix uh is gonna have uh the, the dimensions like say for, for the rows, we expect the number of um neurons that we have in the current layer I and for the columns, we expect the number of neurons uh that we have in the subsequent layer, right? So that's that. And now we want to uh just change it, change this and we want to paint derivatives. And here these activations",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=319s",
        "start_time": "319.679"
    },
    {
        "id": "84af475a",
        "text": "and now we're not expecting a mono dimensional array rather like a two dimensional array, which is basically a matrix. And uh this matrix uh is gonna have uh the, the dimensions like say for, for the rows, we expect the number of um neurons that we have in the current layer I and for the columns, we expect the number of neurons uh that we have in the subsequent layer, right? So that's that. And now we want to uh just change it, change this and we want to paint derivatives. And here these activations again should be changed into uh derivatives. Nice. OK. So now we have a nice way of storing derivatives as well good. So now that we have all like the, the representation place we should go and uh tweak our forward propagate so that we can save the activations. Why we, we, we, we create like we, well, we compute these activations for each layer. So",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=343s",
        "start_time": "343.399"
    },
    {
        "id": "afcb860d",
        "text": "So that's that. And now we want to uh just change it, change this and we want to paint derivatives. And here these activations again should be changed into uh derivatives. Nice. OK. So now we have a nice way of storing derivatives as well good. So now that we have all like the, the representation place we should go and uh tweak our forward propagate so that we can save the activations. Why we, we, we, we create like we, well, we compute these activations for each layer. So uh what about the activation",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=374s",
        "start_time": "374.69"
    },
    {
        "id": "32d9248e",
        "text": "again should be changed into uh derivatives. Nice. OK. So now we have a nice way of storing derivatives as well good. So now that we have all like the, the representation place we should go and uh tweak our forward propagate so that we can save the activations. Why we, we, we, we create like we, well, we compute these activations for each layer. So uh what about the activation self dot uh activations for the first layer for the input layer? Well, we know that uh this is basically just like the inputs, right? So we can save uh the activations for the first layer as the inputs that we are re receiving here as an argument for forward propagate. Nice.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=388s",
        "start_time": "388.649"
    },
    {
        "id": "918528ef",
        "text": "uh what about the activation self dot uh activations for the first layer for the input layer? Well, we know that uh this is basically just like the inputs, right? So we can save uh the activations for the first layer as the inputs that we are re receiving here as an argument for forward propagate. Nice. So now there's uh the next step which is uh this forward propagate iterates through like all the network layers and calculates the activations. And now here at this point, we want to save the activations and now we're gonna save uh the activations at I plus one",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=415s",
        "start_time": "415.679"
    },
    {
        "id": "4d1e91b4",
        "text": "self dot uh activations for the first layer for the input layer? Well, we know that uh this is basically just like the inputs, right? So we can save uh the activations for the first layer as the inputs that we are re receiving here as an argument for forward propagate. Nice. So now there's uh the next step which is uh this forward propagate iterates through like all the network layers and calculates the activations. And now here at this point, we want to save the activations and now we're gonna save uh the activations at I plus one and this is gonna be the activations. So now you may be wondering but uh if you are currently in I right at uh why are we storing this like at I plus one? Well, uh let me show you why that's the case. So if you, you may remember that the activation, say for example, like the activation of the third layer",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=420s",
        "start_time": "420.0"
    },
    {
        "id": "1eeb07e9",
        "text": "So now there's uh the next step which is uh this forward propagate iterates through like all the network layers and calculates the activations. And now here at this point, we want to save the activations and now we're gonna save uh the activations at I plus one and this is gonna be the activations. So now you may be wondering but uh if you are currently in I right at uh why are we storing this like at I plus one? Well, uh let me show you why that's the case. So if you, you may remember that the activation, say for example, like the activation of the third layer is equal to the sigmoid function even like we are only using sigmoid functions as activations functions. Uh It's the sigmoid function of three but now three, if you guys remember",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=441s",
        "start_time": "441.73"
    },
    {
        "id": "bef9f55a",
        "text": "and this is gonna be the activations. So now you may be wondering but uh if you are currently in I right at uh why are we storing this like at I plus one? Well, uh let me show you why that's the case. So if you, you may remember that the activation, say for example, like the activation of the third layer is equal to the sigmoid function even like we are only using sigmoid functions as activations functions. Uh It's the sigmoid function of three but now three, if you guys remember um",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=464s",
        "start_time": "464.63"
    },
    {
        "id": "8582ca2e",
        "text": "is equal to the sigmoid function even like we are only using sigmoid functions as activations functions. Uh It's the sigmoid function of three but now three, if you guys remember um is equal",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=487s",
        "start_time": "487.709"
    },
    {
        "id": "c7873195",
        "text": "um is equal c",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=504s",
        "start_time": "504.5"
    },
    {
        "id": "56d313b4",
        "text": "is equal c the",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=506s",
        "start_time": "506.329"
    },
    {
        "id": "aa91e3ba",
        "text": "c the uh matrix multiplication between A two and um and",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=508s",
        "start_time": "508.67"
    },
    {
        "id": "4177cd8f",
        "text": "the uh matrix multiplication between A two and um and we have W",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=510s",
        "start_time": "510.14"
    },
    {
        "id": "2257cbe0",
        "text": "uh matrix multiplication between A two and um and we have W two, right? And so here, basically we're saying that we are at say for example, this I is equal to two. And so here we are considering like the, the second wave matrix and then the activations connected with the second weight matrix is indeed uh the activation for the third layer. And so here we need to like add one to the current I. So in our example two plus 13, right? And so this is why we're doing this good.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=512s",
        "start_time": "512.848"
    },
    {
        "id": "72687f09",
        "text": "we have W two, right? And so here, basically we're saying that we are at say for example, this I is equal to two. And so here we are considering like the, the second wave matrix and then the activations connected with the second weight matrix is indeed uh the activation for the third layer. And so here we need to like add one to the current I. So in our example two plus 13, right? And so this is why we're doing this good. So nice. So now we have done basically the the the first part of the, the first uh task which is like saving activations and derivatives now uh to well saving just activations because derivatives uh we haven't saved them. We've just like created the representation for saving them, but we'll do that when we implement back propagation, which is happening right now.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=520s",
        "start_time": "520.169"
    },
    {
        "id": "2059917c",
        "text": "two, right? And so here, basically we're saying that we are at say for example, this I is equal to two. And so here we are considering like the, the second wave matrix and then the activations connected with the second weight matrix is indeed uh the activation for the third layer. And so here we need to like add one to the current I. So in our example two plus 13, right? And so this is why we're doing this good. So nice. So now we have done basically the the the first part of the, the first uh task which is like saving activations and derivatives now uh to well saving just activations because derivatives uh we haven't saved them. We've just like created the representation for saving them, but we'll do that when we implement back propagation, which is happening right now. Cool. So now we need to implement a back a new method called back proper",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=522s",
        "start_time": "522.908"
    },
    {
        "id": "b69f8635",
        "text": "So nice. So now we have done basically the the the first part of the, the first uh task which is like saving activations and derivatives now uh to well saving just activations because derivatives uh we haven't saved them. We've just like created the representation for saving them, but we'll do that when we implement back propagation, which is happening right now. Cool. So now we need to implement a back a new method called back proper gauge, right? So now, first of all, we want to pass uh the an error here. So and we'll see like what this error is like in in a few seconds. But first of all, how does this work? So we, we said like in the previous video that with back propagation, the idea is to have the error and uh back propagate the error from the output layer sorry",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=553s",
        "start_time": "553.299"
    },
    {
        "id": "15ecaf23",
        "text": "Cool. So now we need to implement a back a new method called back proper gauge, right? So now, first of all, we want to pass uh the an error here. So and we'll see like what this error is like in in a few seconds. But first of all, how does this work? So we, we said like in the previous video that with back propagation, the idea is to have the error and uh back propagate the error from the output layer sorry towards the uh input layer towards the left, right. So basically what this how, so the way we can translate this in code is that we can basically loop through all the layers starting from like the, the last one towards like the the previous ones, right? And so how do we do that? Well, it's quite simple. So we will do a full loop in a range",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=581s",
        "start_time": "581.07"
    },
    {
        "id": "50a40aec",
        "text": "gauge, right? So now, first of all, we want to pass uh the an error here. So and we'll see like what this error is like in in a few seconds. But first of all, how does this work? So we, we said like in the previous video that with back propagation, the idea is to have the error and uh back propagate the error from the output layer sorry towards the uh input layer towards the left, right. So basically what this how, so the way we can translate this in code is that we can basically loop through all the layers starting from like the, the last one towards like the the previous ones, right? And so how do we do that? Well, it's quite simple. So we will do a full loop in a range uh range of the length of self",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=589s",
        "start_time": "589.9"
    },
    {
        "id": "07a99394",
        "text": "towards the uh input layer towards the left, right. So basically what this how, so the way we can translate this in code is that we can basically loop through all the layers starting from like the, the last one towards like the the previous ones, right? And so how do we do that? Well, it's quite simple. So we will do a full loop in a range uh range of the length of self dot um",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=620s",
        "start_time": "620.44"
    },
    {
        "id": "c5e63c10",
        "text": "uh range of the length of self dot um uh derivatives here.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=646s",
        "start_time": "646.489"
    },
    {
        "id": "1695fdf8",
        "text": "dot um uh derivatives here. So, but this is just like going from left to right, right. Because we are uh incrementing I from zero, like towards like the, the number of like uh elements we have like in self dot derivatives, but we want to go the other way around from right to left. So how do we do that? Well, we just do a reversed",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=652s",
        "start_time": "652.69"
    },
    {
        "id": "6553d3d9",
        "text": "uh derivatives here. So, but this is just like going from left to right, right. Because we are uh incrementing I from zero, like towards like the, the number of like uh elements we have like in self dot derivatives, but we want to go the other way around from right to left. So how do we do that? Well, we just do a reversed of this guy here.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=655s",
        "start_time": "655.4"
    },
    {
        "id": "e705c0ef",
        "text": "So, but this is just like going from left to right, right. Because we are uh incrementing I from zero, like towards like the, the number of like uh elements we have like in self dot derivatives, but we want to go the other way around from right to left. So how do we do that? Well, we just do a reversed of this guy here. Cool. And uh now,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=658s",
        "start_time": "658.869"
    },
    {
        "id": "2fa9fb6b",
        "text": "of this guy here. Cool. And uh now, OK, let me just check.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=682s",
        "start_time": "682.539"
    },
    {
        "id": "71b03408",
        "text": "Cool. And uh now, OK, let me just check. So we may have an issue with the number of parentheses here. No. Yeah, no, it's fine. Good. Uh OK. So now we are just like going through uh we are living through like the, the neural network but starting from uh right, and then moving all the way back towards the inputs.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=686s",
        "start_time": "686.88"
    },
    {
        "id": "426fddcc",
        "text": "OK, let me just check. So we may have an issue with the number of parentheses here. No. Yeah, no, it's fine. Good. Uh OK. So now we are just like going through uh we are living through like the, the neural network but starting from uh right, and then moving all the way back towards the inputs. Now, what should we do? But in order to understand what we should do, we should remember uh like how back propagate uh how back propagation works. And so now I'm gonna pass in some things that I don't want to uh write from scratch because it will take too much time. But if you guys remember,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=690s",
        "start_time": "690.919"
    },
    {
        "id": "8c1ce34d",
        "text": "So we may have an issue with the number of parentheses here. No. Yeah, no, it's fine. Good. Uh OK. So now we are just like going through uh we are living through like the, the neural network but starting from uh right, and then moving all the way back towards the inputs. Now, what should we do? But in order to understand what we should do, we should remember uh like how back propagate uh how back propagation works. And so now I'm gonna pass in some things that I don't want to uh write from scratch because it will take too much time. But if you guys remember, uh let's assume we are like at the uh rightmost weight matrix, right? So say, for example, we are, we have like this network with three layers, then we are like a W-2 and then we want to calculate the error uh with respect the derivative of the error function with respect to uh W-2 or like in this, in this case, like if we want to keep it a general we could say Wy",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=694s",
        "start_time": "694.02"
    },
    {
        "id": "6efc6d13",
        "text": "Now, what should we do? But in order to understand what we should do, we should remember uh like how back propagate uh how back propagation works. And so now I'm gonna pass in some things that I don't want to uh write from scratch because it will take too much time. But if you guys remember, uh let's assume we are like at the uh rightmost weight matrix, right? So say, for example, we are, we have like this network with three layers, then we are like a W-2 and then we want to calculate the error uh with respect the derivative of the error function with respect to uh W-2 or like in this, in this case, like if we want to keep it a general we could say Wy and this is given by this formula down here, right. So if you guys remember, it's basically like this is the error which is the difference between uh why, which is the actual outcome that we are expecting. And the prediction.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=715s",
        "start_time": "715.57"
    },
    {
        "id": "c3f323aa",
        "text": "uh let's assume we are like at the uh rightmost weight matrix, right? So say, for example, we are, we have like this network with three layers, then we are like a W-2 and then we want to calculate the error uh with respect the derivative of the error function with respect to uh W-2 or like in this, in this case, like if we want to keep it a general we could say Wy and this is given by this formula down here, right. So if you guys remember, it's basically like this is the error which is the difference between uh why, which is the actual outcome that we are expecting. And the prediction. And we multiply that by uh the uh derivative of the sigmoid function calculated in uh the net input I plus one. And then we do like a dot pro max multiplication of all of this with uh the activations calculated in I nice",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=736s",
        "start_time": "736.869"
    },
    {
        "id": "761762e5",
        "text": "and this is given by this formula down here, right. So if you guys remember, it's basically like this is the error which is the difference between uh why, which is the actual outcome that we are expecting. And the prediction. And we multiply that by uh the uh derivative of the sigmoid function calculated in uh the net input I plus one. And then we do like a dot pro max multiplication of all of this with uh the activations calculated in I nice good. So the error that we are passing here, this argument is basically this guy here, this error here. So now the next thing that we want to calculate is this Sigma",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=765s",
        "start_time": "765.9"
    },
    {
        "id": "aff61718",
        "text": "And we multiply that by uh the uh derivative of the sigmoid function calculated in uh the net input I plus one. And then we do like a dot pro max multiplication of all of this with uh the activations calculated in I nice good. So the error that we are passing here, this argument is basically this guy here, this error here. So now the next thing that we want to calculate is this Sigma uh prime here, right? But uh what's this Sigma prime calculated in this uh net input here? But well, we can rewrite this like if you remember from the, the previous uh video,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=781s",
        "start_time": "781.539"
    },
    {
        "id": "6f7bd3f4",
        "text": "good. So the error that we are passing here, this argument is basically this guy here, this error here. So now the next thing that we want to calculate is this Sigma uh prime here, right? But uh what's this Sigma prime calculated in this uh net input here? But well, we can rewrite this like if you remember from the, the previous uh video, uh we can rewrite the Sigma prime here as the this derivative. The first derivative is the Sigma Sigma itself calculated in a point and multiplied by minus uh sorry one minus like Sigma calculated in that same point good. But",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=801s",
        "start_time": "801.03"
    },
    {
        "id": "0810bf18",
        "text": "uh prime here, right? But uh what's this Sigma prime calculated in this uh net input here? But well, we can rewrite this like if you remember from the, the previous uh video, uh we can rewrite the Sigma prime here as the this derivative. The first derivative is the Sigma Sigma itself calculated in a point and multiplied by minus uh sorry one minus like Sigma calculated in that same point good. But uh if you remember guys this, the sigma calculated in this point here in I plus one, it's basically the activation",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=815s",
        "start_time": "815.01"
    },
    {
        "id": "f4788f28",
        "text": "uh we can rewrite the Sigma prime here as the this derivative. The first derivative is the Sigma Sigma itself calculated in a point and multiplied by minus uh sorry one minus like Sigma calculated in that same point good. But uh if you remember guys this, the sigma calculated in this point here in I plus one, it's basically the activation calculated in I plus one. And so basically we can get this and just like pop it into uh like this function over here. And we'll get uh the Sigma prime uh information about Sigma prime. So all of this basically to say that we need to retrieve the activations here.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=828s",
        "start_time": "828.799"
    },
    {
        "id": "5f4327c3",
        "text": "uh if you remember guys this, the sigma calculated in this point here in I plus one, it's basically the activation calculated in I plus one. And so basically we can get this and just like pop it into uh like this function over here. And we'll get uh the Sigma prime uh information about Sigma prime. So all of this basically to say that we need to retrieve the activations here. But these activations, we can access them because we've uh saved them in self dot activations but not in uh in uh not the activations in I but in I plus one. So in the subsequent layer, right? And so",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=850s",
        "start_time": "850.19"
    },
    {
        "id": "5d3636c9",
        "text": "calculated in I plus one. And so basically we can get this and just like pop it into uh like this function over here. And we'll get uh the Sigma prime uh information about Sigma prime. So all of this basically to say that we need to retrieve the activations here. But these activations, we can access them because we've uh saved them in self dot activations but not in uh in uh not the activations in I but in I plus one. So in the subsequent layer, right? And so we have this as activations nice. So now if we want to calculate uh this guy here, so the Sigma",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=862s",
        "start_time": "862.679"
    },
    {
        "id": "ba2037ad",
        "text": "But these activations, we can access them because we've uh saved them in self dot activations but not in uh in uh not the activations in I but in I plus one. So in the subsequent layer, right? And so we have this as activations nice. So now if we want to calculate uh this guy here, so the Sigma uh over here,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=886s",
        "start_time": "886.75"
    },
    {
        "id": "3a29411f",
        "text": "we have this as activations nice. So now if we want to calculate uh this guy here, so the Sigma uh over here, so what we need to do is basically do like a uh Sigma uh the first derivative of the Sigma function calculated in this,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=905s",
        "start_time": "905.799"
    },
    {
        "id": "2d30da43",
        "text": "uh over here, so what we need to do is basically do like a uh Sigma uh the first derivative of the Sigma function calculated in this, in these activations, right? But",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=916s",
        "start_time": "916.77"
    },
    {
        "id": "5f09e341",
        "text": "so what we need to do is basically do like a uh Sigma uh the first derivative of the Sigma function calculated in this, in these activations, right? But to do that, we'll do like something slightly uh well, we'll, we'll do like something like uh slightly different now, which is basically calculating delta and we'll define delta as these two elements together. So the error multiplied by the uh first derivative of the Sigma function. So let's do that. So delta is gonna be equal to uh the error",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=919s",
        "start_time": "919.15"
    },
    {
        "id": "75d8f29e",
        "text": "in these activations, right? But to do that, we'll do like something slightly uh well, we'll, we'll do like something like uh slightly different now, which is basically calculating delta and we'll define delta as these two elements together. So the error multiplied by the uh first derivative of the Sigma function. So let's do that. So delta is gonna be equal to uh the error and that's multiplied by self dot uh let's call it seek mo",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=929s",
        "start_time": "929.7"
    },
    {
        "id": "3ba34d19",
        "text": "to do that, we'll do like something slightly uh well, we'll, we'll do like something like uh slightly different now, which is basically calculating delta and we'll define delta as these two elements together. So the error multiplied by the uh first derivative of the Sigma function. So let's do that. So delta is gonna be equal to uh the error and that's multiplied by self dot uh let's call it seek mo uh derivative and we pass in the activations",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=932s",
        "start_time": "932.869"
    },
    {
        "id": "0c96c510",
        "text": "and that's multiplied by self dot uh let's call it seek mo uh derivative and we pass in the activations good. This is nice. But there's an issue here, which is that obviously, we don't have this uh uh function yet because we haven't like defined it. So uh let's build like this method now. So we'll build uh we'll define a new method called underscores mod",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=957s",
        "start_time": "957.969"
    },
    {
        "id": "83c37f5c",
        "text": "uh derivative and we pass in the activations good. This is nice. But there's an issue here, which is that obviously, we don't have this uh uh function yet because we haven't like defined it. So uh let's build like this method now. So we'll build uh we'll define a new method called underscores mod uh derivative",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=967s",
        "start_time": "967.27"
    },
    {
        "id": "be1d4931",
        "text": "good. This is nice. But there's an issue here, which is that obviously, we don't have this uh uh function yet because we haven't like defined it. So uh let's build like this method now. So we'll build uh we'll define a new method called underscores mod uh derivative and uh we'll pass in X and we'll return uh just like look here what this should look like. And so we'll uh return",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=972s",
        "start_time": "972.76"
    },
    {
        "id": "8b14c17c",
        "text": "uh derivative and uh we'll pass in X and we'll return uh just like look here what this should look like. And so we'll uh return X multiplied by",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=996s",
        "start_time": "996.799"
    },
    {
        "id": "1aff2600",
        "text": "and uh we'll pass in X and we'll return uh just like look here what this should look like. And so we'll uh return X multiplied by one",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=999s",
        "start_time": "999.26"
    },
    {
        "id": "136af2d4",
        "text": "X multiplied by one minus",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1012s",
        "start_time": "1012.659"
    },
    {
        "id": "9f2bb28d",
        "text": "one minus X, right?",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1016s",
        "start_time": "1016.46"
    },
    {
        "id": "518f609c",
        "text": "minus X, right? And so we have our sigmoid derivative uh function here nice. So we have delta nice. So which basically means like we have all of this. Now, the uh next step that we need to do is instead of like uh calculating the this guy here, right? So we'll",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1019s",
        "start_time": "1019.52"
    },
    {
        "id": "d41c04c6",
        "text": "X, right? And so we have our sigmoid derivative uh function here nice. So we have delta nice. So which basically means like we have all of this. Now, the uh next step that we need to do is instead of like uh calculating the this guy here, right? So we'll need to, so in order to, to do this, uh we'll need to, to get uh this other activation uh which is the activation cal uh taken like a layer. Uh Like I,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1022s",
        "start_time": "1022.51"
    },
    {
        "id": "500ce94b",
        "text": "And so we have our sigmoid derivative uh function here nice. So we have delta nice. So which basically means like we have all of this. Now, the uh next step that we need to do is instead of like uh calculating the this guy here, right? So we'll need to, so in order to, to do this, uh we'll need to, to get uh this other activation uh which is the activation cal uh taken like a layer. Uh Like I, so we could call this uh current",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1025s",
        "start_time": "1025.02"
    },
    {
        "id": "5c2d7fed",
        "text": "need to, so in order to, to do this, uh we'll need to, to get uh this other activation uh which is the activation cal uh taken like a layer. Uh Like I, so we could call this uh current activation",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1052s",
        "start_time": "1052.92"
    },
    {
        "id": "68faee55",
        "text": "so we could call this uh current activation activations and that's equal to self dot activations. But",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1066s",
        "start_time": "1066.26"
    },
    {
        "id": "3c63c33f",
        "text": "activation activations and that's equal to self dot activations. But at uh I right.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1071s",
        "start_time": "1071.089"
    },
    {
        "id": "8f8ef7a6",
        "text": "activations and that's equal to self dot activations. But at uh I right. Nice. So now, at least in theory, we have like all the elements to",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1072s",
        "start_time": "1072.67"
    },
    {
        "id": "b91f72d6",
        "text": "at uh I right. Nice. So now, at least in theory, we have like all the elements to calculates the derivative in I, right. And uh the derivative in I uh is gonna be given by the dot product",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1080s",
        "start_time": "1080.13"
    },
    {
        "id": "6044b647",
        "text": "Nice. So now, at least in theory, we have like all the elements to calculates the derivative in I, right. And uh the derivative in I uh is gonna be given by the dot product of current activations with delta.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1083s",
        "start_time": "1083.54"
    },
    {
        "id": "e8ddabbe",
        "text": "calculates the derivative in I, right. And uh the derivative in I uh is gonna be given by the dot product of current activations with delta. Nice. And so now we have like the uh the derivative but really, we don't have it yet because uh I'm gonna explain why, but we'll need to do like some trickery which uh like nun pi to organize like this two arrays in a way where we can actually perform this matrix multiplication between the current activations and delta. So uh what we uh want to do uh as the first thing is uh",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1091s",
        "start_time": "1091.8"
    },
    {
        "id": "a5f14d69",
        "text": "of current activations with delta. Nice. And so now we have like the uh the derivative but really, we don't have it yet because uh I'm gonna explain why, but we'll need to do like some trickery which uh like nun pi to organize like this two arrays in a way where we can actually perform this matrix multiplication between the current activations and delta. So uh what we uh want to do uh as the first thing is uh basically rearranging this uh array uh and rearranging it in such a way that it will become a two dimensional array where we only have like a 11 column, right? So it's gonna be basically like a vector sorry, a vertical uh matrix. So what this basically means is that we want to OK. Yeah, let me just comment this. So we want to move from",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1106s",
        "start_time": "1106.949"
    },
    {
        "id": "00450e29",
        "text": "Nice. And so now we have like the uh the derivative but really, we don't have it yet because uh I'm gonna explain why, but we'll need to do like some trickery which uh like nun pi to organize like this two arrays in a way where we can actually perform this matrix multiplication between the current activations and delta. So uh what we uh want to do uh as the first thing is uh basically rearranging this uh array uh and rearranging it in such a way that it will become a two dimensional array where we only have like a 11 column, right? So it's gonna be basically like a vector sorry, a vertical uh matrix. So what this basically means is that we want to OK. Yeah, let me just comment this. So we want to move from uh an array. So we now have",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1113s",
        "start_time": "1113.38"
    },
    {
        "id": "ec8ffdf6",
        "text": "basically rearranging this uh array uh and rearranging it in such a way that it will become a two dimensional array where we only have like a 11 column, right? So it's gonna be basically like a vector sorry, a vertical uh matrix. So what this basically means is that we want to OK. Yeah, let me just comment this. So we want to move from uh an array. So we now have this current activations that's uh an array like this, say it could be like 0.1 and 0.2 and we want to rearrange it so that it has this structure.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1143s",
        "start_time": "1143.239"
    },
    {
        "id": "2282c01c",
        "text": "uh an array. So we now have this current activations that's uh an array like this, say it could be like 0.1 and 0.2 and we want to rearrange it so that it has this structure. So you're set here o sorry,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1172s",
        "start_time": "1172.04"
    },
    {
        "id": "9d9a45f6",
        "text": "this current activations that's uh an array like this, say it could be like 0.1 and 0.2 and we want to rearrange it so that it has this structure. So you're set here o sorry, like this.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1176s",
        "start_time": "1176.979"
    },
    {
        "id": "710bbaf1",
        "text": "So you're set here o sorry, like this. OK.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1192s",
        "start_time": "1192.88"
    },
    {
        "id": "f59ba3d9",
        "text": "like this. OK. So basically, this is gonna be like a two D array and uh it, it's gonna be like basically like a, a vertical uh vector, right?",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1197s",
        "start_time": "1197.229"
    },
    {
        "id": "8fe7c3e1",
        "text": "OK. So basically, this is gonna be like a two D array and uh it, it's gonna be like basically like a, a vertical uh vector, right? Good. So how do we do that? Well, we need to do like some uh trickery uh with NP. So we'll do that, the current activations. Uh Let's call it uh reshaped,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1198s",
        "start_time": "1198.989"
    },
    {
        "id": "d173153c",
        "text": "So basically, this is gonna be like a two D array and uh it, it's gonna be like basically like a, a vertical uh vector, right? Good. So how do we do that? Well, we need to do like some uh trickery uh with NP. So we'll do that, the current activations. Uh Let's call it uh reshaped, it's equal to current activations. And then we need to call the uh reshape method which is a native method in NPI. And, and so here we need to do this thing.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1201s",
        "start_time": "1201.199"
    },
    {
        "id": "451bbc6d",
        "text": "Good. So how do we do that? Well, we need to do like some uh trickery uh with NP. So we'll do that, the current activations. Uh Let's call it uh reshaped, it's equal to current activations. And then we need to call the uh reshape method which is a native method in NPI. And, and so here we need to do this thing. So current activations dot shape uh and we take like the uh the shape like of the uh the first uh like index and then we do uh like a minus one. So doing this, we'll just move uh like we restructure our array from like this",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1213s",
        "start_time": "1213.469"
    },
    {
        "id": "82e0f525",
        "text": "it's equal to current activations. And then we need to call the uh reshape method which is a native method in NPI. And, and so here we need to do this thing. So current activations dot shape uh and we take like the uh the shape like of the uh the first uh like index and then we do uh like a minus one. So doing this, we'll just move uh like we restructure our array from like this to this, right? And so, and now we just need to change this over here and we've uh like input the current activations re shape. Now, we need to do something similar for uh delta as well. So we need a delta",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1228s",
        "start_time": "1228.069"
    },
    {
        "id": "a1b3289f",
        "text": "So current activations dot shape uh and we take like the uh the shape like of the uh the first uh like index and then we do uh like a minus one. So doing this, we'll just move uh like we restructure our array from like this to this, right? And so, and now we just need to change this over here and we've uh like input the current activations re shape. Now, we need to do something similar for uh delta as well. So we need a delta reshaped",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1245s",
        "start_time": "1245.209"
    },
    {
        "id": "667aa052",
        "text": "to this, right? And so, and now we just need to change this over here and we've uh like input the current activations re shape. Now, we need to do something similar for uh delta as well. So we need a delta reshaped good. But uh let's take a look at what we want to do first. So",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1265s",
        "start_time": "1265.579"
    },
    {
        "id": "b253b133",
        "text": "reshaped good. But uh let's take a look at what we want to do first. So for delta, so uh let me like rewrite this like this. So we are starting with a similar uh array. So which is like a one dimensional array. And then what we want to achieve now is a ND a two dimensional array where",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1285s",
        "start_time": "1285.209"
    },
    {
        "id": "a3af9de0",
        "text": "good. But uh let's take a look at what we want to do first. So for delta, so uh let me like rewrite this like this. So we are starting with a similar uh array. So which is like a one dimensional array. And then what we want to achieve now is a ND a two dimensional array where we,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1289s",
        "start_time": "1289.219"
    },
    {
        "id": "bd30b5cf",
        "text": "for delta, so uh let me like rewrite this like this. So we are starting with a similar uh array. So which is like a one dimensional array. And then what we want to achieve now is a ND a two dimensional array where we, well, just give me a sec here",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1294s",
        "start_time": "1294.91"
    },
    {
        "id": "e9a51916",
        "text": "we, well, just give me a sec here where we have this, right. So it's basically just like a two dimensional array with a single uh row. So how do we do that? Well, we can do like something very similar to this uh to what we've done with the current activations. But obviously, in, instead of uh current activations, we should use delta, we use delta. And then here we have a, obviously like after we perform this reshape",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1315s",
        "start_time": "1315.709"
    },
    {
        "id": "77e3364e",
        "text": "well, just give me a sec here where we have this, right. So it's basically just like a two dimensional array with a single uh row. So how do we do that? Well, we can do like something very similar to this uh to what we've done with the current activations. But obviously, in, instead of uh current activations, we should use delta, we use delta. And then here we have a, obviously like after we perform this reshape until now here we have a vertical uh matrix. And so if we do dot T capital T, this will transpose the um",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1317s",
        "start_time": "1317.05"
    },
    {
        "id": "f28aa100",
        "text": "where we have this, right. So it's basically just like a two dimensional array with a single uh row. So how do we do that? Well, we can do like something very similar to this uh to what we've done with the current activations. But obviously, in, instead of uh current activations, we should use delta, we use delta. And then here we have a, obviously like after we perform this reshape until now here we have a vertical uh matrix. And so if we do dot T capital T, this will transpose the um uh the array. And so we will basically move from a structure",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1321s",
        "start_time": "1321.229"
    },
    {
        "id": "e6819289",
        "text": "until now here we have a vertical uh matrix. And so if we do dot T capital T, this will transpose the um uh the array. And so we will basically move from a structure like this one to a structure like this",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1349s",
        "start_time": "1349.89"
    },
    {
        "id": "65c85a39",
        "text": "uh the array. And so we will basically move from a structure like this one to a structure like this nice. So now we have everything in place to do uh uh our to calculate like our derivative uh here.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1361s",
        "start_time": "1361.979"
    },
    {
        "id": "ab18bef9",
        "text": "like this one to a structure like this nice. So now we have everything in place to do uh uh our to calculate like our derivative uh here. And so yeah,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1366s",
        "start_time": "1366.77"
    },
    {
        "id": "44d0a119",
        "text": "nice. So now we have everything in place to do uh uh our to calculate like our derivative uh here. And so yeah, this is like basically all we need to do for like the, the first",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1372s",
        "start_time": "1372.239"
    },
    {
        "id": "13c0da24",
        "text": "And so yeah, this is like basically all we need to do for like the, the first parts over here like of our back propagation. So for the utmost uh uh like weight weight matrix. So when we do like the uh the derivative of the error function with respect to uh w uh calculated in I right.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1382s",
        "start_time": "1382.31"
    },
    {
        "id": "17072c83",
        "text": "this is like basically all we need to do for like the, the first parts over here like of our back propagation. So for the utmost uh uh like weight weight matrix. So when we do like the uh the derivative of the error function with respect to uh w uh calculated in I right. OK. So now we know though that uh we, we want to just like go back one step and uh do uh a another like derivative of the area of function. But this time in uh w of I minus one.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1384s",
        "start_time": "1384.439"
    },
    {
        "id": "006130e1",
        "text": "parts over here like of our back propagation. So for the utmost uh uh like weight weight matrix. So when we do like the uh the derivative of the error function with respect to uh w uh calculated in I right. OK. So now we know though that uh we, we want to just like go back one step and uh do uh a another like derivative of the area of function. But this time in uh w of I minus one. So, and how do we do that uh like with a formula and we've already sent this and I'm gonna just like copy, paste it here just like because like it's, it's easier,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1391s",
        "start_time": "1391.979"
    },
    {
        "id": "13265261",
        "text": "OK. So now we know though that uh we, we want to just like go back one step and uh do uh a another like derivative of the area of function. But this time in uh w of I minus one. So, and how do we do that uh like with a formula and we've already sent this and I'm gonna just like copy, paste it here just like because like it's, it's easier, right? And so as you see here, so when we are calculating the next",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1409s",
        "start_time": "1409.369"
    },
    {
        "id": "9112cb84",
        "text": "So, and how do we do that uh like with a formula and we've already sent this and I'm gonna just like copy, paste it here just like because like it's, it's easier, right? And so as you see here, so when we are calculating the next um derivative towards the left, what we, what we are going to bring back uh from the previous um derivative that we've calculated is this guy here, right? So the",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1429s",
        "start_time": "1429.189"
    },
    {
        "id": "f513e1b1",
        "text": "right? And so as you see here, so when we are calculating the next um derivative towards the left, what we, what we are going to bring back uh from the previous um derivative that we've calculated is this guy here, right? So the delta itself. So delta is gonna be like moved uh to pushed back to towards like the, the first the, the previous uh layer. But along with that given like we are like at I right now, we could also calculate all of this. So basically doing um",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1440s",
        "start_time": "1440.91"
    },
    {
        "id": "ffb9cced",
        "text": "um derivative towards the left, what we, what we are going to bring back uh from the previous um derivative that we've calculated is this guy here, right? So the delta itself. So delta is gonna be like moved uh to pushed back to towards like the, the first the, the previous uh layer. But along with that given like we are like at I right now, we could also calculate all of this. So basically doing um we're going to calculate a new error here, which is going to be given by the NP",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1446s",
        "start_time": "1446.91"
    },
    {
        "id": "00c41881",
        "text": "delta itself. So delta is gonna be like moved uh to pushed back to towards like the, the first the, the previous uh layer. But along with that given like we are like at I right now, we could also calculate all of this. So basically doing um we're going to calculate a new error here, which is going to be given by the NP dots. So we want to do a matrix multiplication here between delta itself.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1463s",
        "start_time": "1463.349"
    },
    {
        "id": "055aaafe",
        "text": "we're going to calculate a new error here, which is going to be given by the NP dots. So we want to do a matrix multiplication here between delta itself. And",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1486s",
        "start_time": "1486.0"
    },
    {
        "id": "7121f38f",
        "text": "dots. So we want to do a matrix multiplication here between delta itself. And we want to do that with the with the weights with the weight matrix.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1496s",
        "start_time": "1496.66"
    },
    {
        "id": "467aab3d",
        "text": "And we want to do that with the with the weights with the weight matrix. So it's this guy here",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1505s",
        "start_time": "1505.329"
    },
    {
        "id": "b921dcfc",
        "text": "we want to do that with the with the weights with the weight matrix. So it's this guy here uh for the I uh layer and here we need like to do just like the transpose uh matrix for that.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1507s",
        "start_time": "1507.13"
    },
    {
        "id": "e6dda6c9",
        "text": "So it's this guy here uh for the I uh layer and here we need like to do just like the transpose uh matrix for that. Uh cool. So now this error here is basically all of this guy here.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1514s",
        "start_time": "1514.699"
    },
    {
        "id": "84d8a3ac",
        "text": "uh for the I uh layer and here we need like to do just like the transpose uh matrix for that. Uh cool. So now this error here is basically all of this guy here. So",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1517s",
        "start_time": "1517.579"
    },
    {
        "id": "c5ab84b2",
        "text": "Uh cool. So now this error here is basically all of this guy here. So now that we are here, you'll see that we are just like gonna start another loop and we are going down with I. So if the first time it was like, I equal two, now we're going for I equal one. So we are gonna do the derivatives for W one,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1527s",
        "start_time": "1527.229"
    },
    {
        "id": "ec6e87f5",
        "text": "So now that we are here, you'll see that we are just like gonna start another loop and we are going down with I. So if the first time it was like, I equal two, now we're going for I equal one. So we are gonna do the derivatives for W one, right? And so uh now we're just gonna do like the same thing once again. Uh But uh this time we have our error and our error is given by all of this guy here, which we calculated in the previous passage in the previous um iteration.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1534s",
        "start_time": "1534.709"
    },
    {
        "id": "0d30042b",
        "text": "now that we are here, you'll see that we are just like gonna start another loop and we are going down with I. So if the first time it was like, I equal two, now we're going for I equal one. So we are gonna do the derivatives for W one, right? And so uh now we're just gonna do like the same thing once again. Uh But uh this time we have our error and our error is given by all of this guy here, which we calculated in the previous passage in the previous um iteration. And now we are calculating delta uh which this time around is gonna be like this guy. And then we are gonna calculate uh this derivative here by doing the matrix multiplication between the current activations and which are like which is this and the delta reshaped like over here. Nice. And so now we can",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1536s",
        "start_time": "1536.42"
    },
    {
        "id": "1b6bd4d6",
        "text": "right? And so uh now we're just gonna do like the same thing once again. Uh But uh this time we have our error and our error is given by all of this guy here, which we calculated in the previous passage in the previous um iteration. And now we are calculating delta uh which this time around is gonna be like this guy. And then we are gonna calculate uh this derivative here by doing the matrix multiplication between the current activations and which are like which is this and the delta reshaped like over here. Nice. And so now we can go all the way back until we are like at the input level. So I know like this was like a little bit, I would say like more difficult to understand than like a simple case where we have like hard wired or like layers. But with this back propagation, we can have potentially infinite layers. And this back pro back propagate method is gonna work for all of them. Nice.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1553s",
        "start_time": "1553.599"
    },
    {
        "id": "b239b072",
        "text": "And now we are calculating delta uh which this time around is gonna be like this guy. And then we are gonna calculate uh this derivative here by doing the matrix multiplication between the current activations and which are like which is this and the delta reshaped like over here. Nice. And so now we can go all the way back until we are like at the input level. So I know like this was like a little bit, I would say like more difficult to understand than like a simple case where we have like hard wired or like layers. But with this back propagation, we can have potentially infinite layers. And this back pro back propagate method is gonna work for all of them. Nice. So now as the final thing, we could potentially return uh the error which in this case is going to be the error back propagated all the way back to the input layer",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1572s",
        "start_time": "1572.359"
    },
    {
        "id": "5c8b385e",
        "text": "go all the way back until we are like at the input level. So I know like this was like a little bit, I would say like more difficult to understand than like a simple case where we have like hard wired or like layers. But with this back propagation, we can have potentially infinite layers. And this back pro back propagate method is gonna work for all of them. Nice. So now as the final thing, we could potentially return uh the error which in this case is going to be the error back propagated all the way back to the input layer good.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1600s",
        "start_time": "1600.05"
    },
    {
        "id": "b56491cf",
        "text": "So now as the final thing, we could potentially return uh the error which in this case is going to be the error back propagated all the way back to the input layer good. OK. So this was uh like back propagation. So I suggest now like we uh do uh try to like run the code up until like what we've done uh like now to see like if everything is OK? Because we may have like some bugs because we don't know.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1625s",
        "start_time": "1625.78"
    },
    {
        "id": "10d66a0c",
        "text": "good. OK. So this was uh like back propagation. So I suggest now like we uh do uh try to like run the code up until like what we've done uh like now to see like if everything is OK? Because we may have like some bugs because we don't know. Right. So OK. So first of all,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1638s",
        "start_time": "1638.239"
    },
    {
        "id": "542876b6",
        "text": "OK. So this was uh like back propagation. So I suggest now like we uh do uh try to like run the code up until like what we've done uh like now to see like if everything is OK? Because we may have like some bugs because we don't know. Right. So OK. So first of all, yeah, let me",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1639s",
        "start_time": "1639.739"
    },
    {
        "id": "cb3bf6ef",
        "text": "Right. So OK. So first of all, yeah, let me to",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1658s",
        "start_time": "1658.16"
    },
    {
        "id": "73ecad53",
        "text": "yeah, let me to this if name is equal to main. And so here we are like ensuring that we run this like as the main script uh good. So what do we want to do here? Well, uh first of all, uh we want to um create uh an M LP,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1663s",
        "start_time": "1663.38"
    },
    {
        "id": "62decd32",
        "text": "to this if name is equal to main. And so here we are like ensuring that we run this like as the main script uh good. So what do we want to do here? Well, uh first of all, uh we want to um create uh an M LP, it's a multi layer uh perception and then we want to Yeah. Yeah, let's just like create a dummy,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1665s",
        "start_time": "1665.319"
    },
    {
        "id": "536f341b",
        "text": "this if name is equal to main. And so here we are like ensuring that we run this like as the main script uh good. So what do we want to do here? Well, uh first of all, uh we want to um create uh an M LP, it's a multi layer uh perception and then we want to Yeah. Yeah, let's just like create a dummy, data domain, inputs and targets and then we're gonna pass uh this data so to forward propagate. Uh So we, we'll do like a forward uh propagation and then we'll do a back propagation",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1667s",
        "start_time": "1667.349"
    },
    {
        "id": "f2ed57c1",
        "text": "it's a multi layer uh perception and then we want to Yeah. Yeah, let's just like create a dummy, data domain, inputs and targets and then we're gonna pass uh this data so to forward propagate. Uh So we, we'll do like a forward uh propagation and then we'll do a back propagation good.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1689s",
        "start_time": "1689.54"
    },
    {
        "id": "6321056e",
        "text": "data domain, inputs and targets and then we're gonna pass uh this data so to forward propagate. Uh So we, we'll do like a forward uh propagation and then we'll do a back propagation good. OK. So let's start by creating an M LP. So that's quite simple now because we already know",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1698s",
        "start_time": "1698.599"
    },
    {
        "id": "66f91065",
        "text": "good. OK. So let's start by creating an M LP. So that's quite simple now because we already know and we have this guy here. And so let's say here we should pass the number of like um inputs, the number of hidden layers and the number of outputs. So let's do something like this. So two neurons for the input layers. So now we want only a one hidden layer which say like five neurons and then we have just one neuron for the output layer good.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1718s",
        "start_time": "1718.349"
    },
    {
        "id": "6349ee73",
        "text": "OK. So let's start by creating an M LP. So that's quite simple now because we already know and we have this guy here. And so let's say here we should pass the number of like um inputs, the number of hidden layers and the number of outputs. So let's do something like this. So two neurons for the input layers. So now we want only a one hidden layer which say like five neurons and then we have just one neuron for the output layer good. OK. So now let's create some dummy uh data. So we'll create uh an input and this input is going to be an array where we pass in couple of numbers, right?",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1719s",
        "start_time": "1719.489"
    },
    {
        "id": "0a492fac",
        "text": "and we have this guy here. And so let's say here we should pass the number of like um inputs, the number of hidden layers and the number of outputs. So let's do something like this. So two neurons for the input layers. So now we want only a one hidden layer which say like five neurons and then we have just one neuron for the output layer good. OK. So now let's create some dummy uh data. So we'll create uh an input and this input is going to be an array where we pass in couple of numbers, right? And why should we pass a couple of numbers here? Because we have like two neurons and basically each of these guys uh in the array is gonna uh go to one of the two different neurons, right? OK. So we have the input and now we want the, the target",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1727s",
        "start_time": "1727.41"
    },
    {
        "id": "3151eac3",
        "text": "OK. So now let's create some dummy uh data. So we'll create uh an input and this input is going to be an array where we pass in couple of numbers, right? And why should we pass a couple of numbers here? Because we have like two neurons and basically each of these guys uh in the array is gonna uh go to one of the two different neurons, right? OK. So we have the input and now we want the, the target and the target is gonna be",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1752s",
        "start_time": "1752.26"
    },
    {
        "id": "ae5cf032",
        "text": "And why should we pass a couple of numbers here? Because we have like two neurons and basically each of these guys uh in the array is gonna uh go to one of the two different neurons, right? OK. So we have the input and now we want the, the target and the target is gonna be uh itself a a an array and uh let's say 0.3. So you probably are seeing what I'm doing here. So I'm expecting a the sum like of these two numbers, right? So I hope like my network is gonna uh like learn how to do the sum operation. And yeah, that's what we are gonna use like as a uh as a task dummy like toy task like for uh this video",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1768s",
        "start_time": "1768.17"
    },
    {
        "id": "c5581586",
        "text": "and the target is gonna be uh itself a a an array and uh let's say 0.3. So you probably are seeing what I'm doing here. So I'm expecting a the sum like of these two numbers, right? So I hope like my network is gonna uh like learn how to do the sum operation. And yeah, that's what we are gonna use like as a uh as a task dummy like toy task like for uh this video good. So, but here just we have just a single input and a single target. That's all we need uh for now. So what should we do now? Well, Uh First of all, we should do an M LP dot forward propagate and we want to pass the input in. And so we'll pass this guy here and then we'll do a back uh propagation here. So M LP dot",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1785s",
        "start_time": "1785.13"
    },
    {
        "id": "6ee85ff4",
        "text": "uh itself a a an array and uh let's say 0.3. So you probably are seeing what I'm doing here. So I'm expecting a the sum like of these two numbers, right? So I hope like my network is gonna uh like learn how to do the sum operation. And yeah, that's what we are gonna use like as a uh as a task dummy like toy task like for uh this video good. So, but here just we have just a single input and a single target. That's all we need uh for now. So what should we do now? Well, Uh First of all, we should do an M LP dot forward propagate and we want to pass the input in. And so we'll pass this guy here and then we'll do a back uh propagation here. So M LP dot back propagate and obviously, we are expecting an output over here",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1790s",
        "start_time": "1790.01"
    },
    {
        "id": "a46fb667",
        "text": "good. So, but here just we have just a single input and a single target. That's all we need uh for now. So what should we do now? Well, Uh First of all, we should do an M LP dot forward propagate and we want to pass the input in. And so we'll pass this guy here and then we'll do a back uh propagation here. So M LP dot back propagate and obviously, we are expecting an output over here uh which is basically like the, the uh after like all the computation has been done uh like on the inputs we're getting like the prediction, which is this output. Well, uh I forgot to mention one step here uh before doing back propagation. And you should know by now what that step should be and it's calculates uh the error, right? So, and how do we calculate the error? So, well, we calculate the error doing a target",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1817s",
        "start_time": "1817.959"
    },
    {
        "id": "70a34385",
        "text": "back propagate and obviously, we are expecting an output over here uh which is basically like the, the uh after like all the computation has been done uh like on the inputs we're getting like the prediction, which is this output. Well, uh I forgot to mention one step here uh before doing back propagation. And you should know by now what that step should be and it's calculates uh the error, right? So, and how do we calculate the error? So, well, we calculate the error doing a target minus the oh",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1847s",
        "start_time": "1847.01"
    },
    {
        "id": "6d044248",
        "text": "uh which is basically like the, the uh after like all the computation has been done uh like on the inputs we're getting like the prediction, which is this output. Well, uh I forgot to mention one step here uh before doing back propagation. And you should know by now what that step should be and it's calculates uh the error, right? So, and how do we calculate the error? So, well, we calculate the error doing a target minus the oh the output.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1854s",
        "start_time": "1854.959"
    },
    {
        "id": "67004cef",
        "text": "minus the oh the output. And then when we do uh back propagation, we'll just pass in the error, right?",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1884s",
        "start_time": "1884.38"
    },
    {
        "id": "ed55f587",
        "text": "the output. And then when we do uh back propagation, we'll just pass in the error, right? OK.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1887s",
        "start_time": "1887.959"
    },
    {
        "id": "46985cfb",
        "text": "And then when we do uh back propagation, we'll just pass in the error, right? OK. So uh let's try to see if uh we get what we expect uh from uh back propagation. So",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1890s",
        "start_time": "1890.219"
    },
    {
        "id": "100c8ac8",
        "text": "OK. So uh let's try to see if uh we get what we expect uh from uh back propagation. So I'd say",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1899s",
        "start_time": "1899.03"
    },
    {
        "id": "966630c1",
        "text": "So uh let's try to see if uh we get what we expect uh from uh back propagation. So I'd say what we could do here is we could",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1900s",
        "start_time": "1900.31"
    },
    {
        "id": "d1c5b351",
        "text": "I'd say what we could do here is we could uh",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1911s",
        "start_time": "1911.18"
    },
    {
        "id": "7f67db8c",
        "text": "what we could do here is we could uh have for the timing, a verbose",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1913s",
        "start_time": "1913.18"
    },
    {
        "id": "dd2a54c9",
        "text": "uh have for the timing, a verbose argument which will set as false initially. And then we say",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1918s",
        "start_time": "1918.04"
    },
    {
        "id": "f14cea2f",
        "text": "have for the timing, a verbose argument which will set as false initially. And then we say if the boys,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1919s",
        "start_time": "1919.319"
    },
    {
        "id": "5451d459",
        "text": "argument which will set as false initially. And then we say if the boys, so if we are in verbose merge, then we want to print",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1925s",
        "start_time": "1925.089"
    },
    {
        "id": "9991bc9d",
        "text": "if the boys, so if we are in verbose merge, then we want to print uh what do we want to print here? Well, we want to print the uh derivatives that we've calculated uh like uh for like a specific weight matrix. So how do we do that? Well, uh we do that by saying",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1932s",
        "start_time": "1932.02"
    },
    {
        "id": "67b11d67",
        "text": "so if we are in verbose merge, then we want to print uh what do we want to print here? Well, we want to print the uh derivatives that we've calculated uh like uh for like a specific weight matrix. So how do we do that? Well, uh we do that by saying uh derivatives",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1935s",
        "start_time": "1935.069"
    },
    {
        "id": "647d7b17",
        "text": "uh what do we want to print here? Well, we want to print the uh derivatives that we've calculated uh like uh for like a specific weight matrix. So how do we do that? Well, uh we do that by saying uh derivatives four",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1939s",
        "start_time": "1939.849"
    },
    {
        "id": "4c11cb75",
        "text": "uh derivatives four W",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1958s",
        "start_time": "1958.209"
    },
    {
        "id": "0fc2f173",
        "text": "four W and then here we'll say",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1962s",
        "start_time": "1962.459"
    },
    {
        "id": "d2193508",
        "text": "W and then here we'll say uh I,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1966s",
        "start_time": "1966.13"
    },
    {
        "id": "66d97396",
        "text": "and then here we'll say uh I, and yeah, and I think like we are like uh",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1967s",
        "start_time": "1967.739"
    },
    {
        "id": "f5cdfbf5",
        "text": "uh I, and yeah, and I think like we are like uh uh this is, this is equal",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1971s",
        "start_time": "1971.489"
    },
    {
        "id": "deb62c9d",
        "text": "and yeah, and I think like we are like uh uh this is, this is equal two",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1973s",
        "start_time": "1973.78"
    },
    {
        "id": "15621d13",
        "text": "uh this is, this is equal two uh",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1978s",
        "start_time": "1978.39"
    },
    {
        "id": "0329c038",
        "text": "two uh uh to this uh self derivatives calculated in I good.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1983s",
        "start_time": "1983.589"
    },
    {
        "id": "c51df0bf",
        "text": "uh uh to this uh self derivatives calculated in I good. OK. Cool. So fingers crossed, this should work until like we've made some mistakes in the process. So let's see if this works.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1985s",
        "start_time": "1985.93"
    },
    {
        "id": "fd152545",
        "text": "uh to this uh self derivatives calculated in I good. OK. Cool. So fingers crossed, this should work until like we've made some mistakes in the process. So let's see if this works. Yeah.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1986s",
        "start_time": "1986.969"
    },
    {
        "id": "4f2341e8",
        "text": "OK. Cool. So fingers crossed, this should work until like we've made some mistakes in the process. So let's see if this works. Yeah. Well, obviously I've run this but I should pass in the verbose",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=1993s",
        "start_time": "1993.729"
    },
    {
        "id": "5ac3d213",
        "text": "Yeah. Well, obviously I've run this but I should pass in the verbose uh equals true. Like if you, if you want to see like something coming up.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2004s",
        "start_time": "2004.91"
    },
    {
        "id": "17655db0",
        "text": "Well, obviously I've run this but I should pass in the verbose uh equals true. Like if you, if you want to see like something coming up. So let's say this. Oh Nice, nice.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2007s",
        "start_time": "2007.5"
    },
    {
        "id": "071d6959",
        "text": "uh equals true. Like if you, if you want to see like something coming up. So let's say this. Oh Nice, nice. So what do we have here? So we have the derivatives for W one. And indeed, we are expecting this structure like for like this matrix which is like uh basically five by one. So it's just like a column",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2014s",
        "start_time": "2014.55"
    },
    {
        "id": "4515b74a",
        "text": "So let's say this. Oh Nice, nice. So what do we have here? So we have the derivatives for W one. And indeed, we are expecting this structure like for like this matrix which is like uh basically five by one. So it's just like a column matrix. And why is that the case? Well, because we have five neurons like in the, in this hidden layer and just like one neuron here like as the uh output layer. And so we expect like a five by one matrix there for W",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2019s",
        "start_time": "2019.56"
    },
    {
        "id": "dac83034",
        "text": "So what do we have here? So we have the derivatives for W one. And indeed, we are expecting this structure like for like this matrix which is like uh basically five by one. So it's just like a column matrix. And why is that the case? Well, because we have five neurons like in the, in this hidden layer and just like one neuron here like as the uh output layer. And so we expect like a five by one matrix there for W uh one, right? So now for W zero over here, which is gonna be like between like the input layer and the, and the first hidden layer or the only hidden layer. So we are expecting a matrix which should be",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2023s",
        "start_time": "2023.219"
    },
    {
        "id": "031b7816",
        "text": "matrix. And why is that the case? Well, because we have five neurons like in the, in this hidden layer and just like one neuron here like as the uh output layer. And so we expect like a five by one matrix there for W uh one, right? So now for W zero over here, which is gonna be like between like the input layer and the, and the first hidden layer or the only hidden layer. So we are expecting a matrix which should be and we have it here uh two by five. And indeed we have it. So as you see it here, we have like five different values for each row. And that's like what we were expecting. So we are like on, on, on the right path here, but it ain't finished yet. So we, we should keep like moving on.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2040s",
        "start_time": "2040.31"
    },
    {
        "id": "4d4d7c3a",
        "text": "uh one, right? So now for W zero over here, which is gonna be like between like the input layer and the, and the first hidden layer or the only hidden layer. So we are expecting a matrix which should be and we have it here uh two by five. And indeed we have it. So as you see it here, we have like five different values for each row. And that's like what we were expecting. So we are like on, on, on the right path here, but it ain't finished yet. So we, we should keep like moving on. And so what we've done so far is we've activated. So we saved the activations and the derivatives, we've implemented back propagation. Now, we need to implement guardian descent. But I promise this is gonna be like way, way faster than back propagation because it's quite straightforward. So good. OK. So let's move on uh with uh a new method which will call gradient uh the scent.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2058s",
        "start_time": "2058.878"
    },
    {
        "id": "28907403",
        "text": "and we have it here uh two by five. And indeed we have it. So as you see it here, we have like five different values for each row. And that's like what we were expecting. So we are like on, on, on the right path here, but it ain't finished yet. So we, we should keep like moving on. And so what we've done so far is we've activated. So we saved the activations and the derivatives, we've implemented back propagation. Now, we need to implement guardian descent. But I promise this is gonna be like way, way faster than back propagation because it's quite straightforward. So good. OK. So let's move on uh with uh a new method which will call gradient uh the scent. And here,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2080s",
        "start_time": "2080.01"
    },
    {
        "id": "453a656d",
        "text": "And so what we've done so far is we've activated. So we saved the activations and the derivatives, we've implemented back propagation. Now, we need to implement guardian descent. But I promise this is gonna be like way, way faster than back propagation because it's quite straightforward. So good. OK. So let's move on uh with uh a new method which will call gradient uh the scent. And here, so we need to pass an argument. This is called the learning rate. And we've seen this in the last video and this is like the, the size of the step we want to take against the gradient uh just like to optimize uh our uh error function, right?",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2102s",
        "start_time": "2102.03"
    },
    {
        "id": "ef681d7d",
        "text": "And here, so we need to pass an argument. This is called the learning rate. And we've seen this in the last video and this is like the, the size of the step we want to take against the gradient uh just like to optimize uh our uh error function, right? Uh good. So now, what should we do?",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2132s",
        "start_time": "2132.26"
    },
    {
        "id": "6481f62c",
        "text": "so we need to pass an argument. This is called the learning rate. And we've seen this in the last video and this is like the, the size of the step we want to take against the gradient uh just like to optimize uh our uh error function, right? Uh good. So now, what should we do? Well,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2134s",
        "start_time": "2134.439"
    },
    {
        "id": "27da119c",
        "text": "Uh good. So now, what should we do? Well, uh so now we should go loop through all the weights.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2153s",
        "start_time": "2153.189"
    },
    {
        "id": "17fa1ef3",
        "text": "Well, uh so now we should go loop through all the weights. And so we're gonna do that by doing a four loop in, we could say on a range L",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2159s",
        "start_time": "2159.57"
    },
    {
        "id": "c56a1c06",
        "text": "uh so now we should go loop through all the weights. And so we're gonna do that by doing a four loop in, we could say on a range L of self dot uh weights. So we are going through like all the uh different, sorry, different weight mattresses. And then we can say that the weight uh weight mattress matrix for",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2160s",
        "start_time": "2160.989"
    },
    {
        "id": "602cc10a",
        "text": "And so we're gonna do that by doing a four loop in, we could say on a range L of self dot uh weights. So we are going through like all the uh different, sorry, different weight mattresses. And then we can say that the weight uh weight mattress matrix for bye",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2167s",
        "start_time": "2167.959"
    },
    {
        "id": "6a0bfd11",
        "text": "of self dot uh weights. So we are going through like all the uh different, sorry, different weight mattresses. And then we can say that the weight uh weight mattress matrix for bye the current layer over here. It's gonna be self weights calculated uh like N I and we can do like the the sa me thing uh with derivatives. So we'll just change this to.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2178s",
        "start_time": "2178.51"
    },
    {
        "id": "f98f0682",
        "text": "bye the current layer over here. It's gonna be self weights calculated uh like N I and we can do like the the sa me thing uh with derivatives. So we'll just change this to. And so basically we are getting uh we are retrieving the weights and the relative derivatives for a given layer, right? And so what we want to do here is to update the weights and to update the weights. If you guys remember if you're good students, you may, you should know this by now because we've covered this last in the last video. But what we should do here is",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2196s",
        "start_time": "2196.34"
    },
    {
        "id": "cdfe6a26",
        "text": "the current layer over here. It's gonna be self weights calculated uh like N I and we can do like the the sa me thing uh with derivatives. So we'll just change this to. And so basically we are getting uh we are retrieving the weights and the relative derivatives for a given layer, right? And so what we want to do here is to update the weights and to update the weights. If you guys remember if you're good students, you may, you should know this by now because we've covered this last in the last video. But what we should do here is uh taking the weights and um we should",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2197s",
        "start_time": "2197.36"
    },
    {
        "id": "15fb2b19",
        "text": "And so basically we are getting uh we are retrieving the weights and the relative derivatives for a given layer, right? And so what we want to do here is to update the weights and to update the weights. If you guys remember if you're good students, you may, you should know this by now because we've covered this last in the last video. But what we should do here is uh taking the weights and um we should add to the weight, the derivatives",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2214s",
        "start_time": "2214.679"
    },
    {
        "id": "b7259093",
        "text": "uh taking the weights and um we should add to the weight, the derivatives multiplied by the learning rate. Nice. So let's rewrite this in a more compact way. And so we can just like",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2240s",
        "start_time": "2240.209"
    },
    {
        "id": "286d1b08",
        "text": "add to the weight, the derivatives multiplied by the learning rate. Nice. So let's rewrite this in a more compact way. And so we can just like do this. It's the same thing. So we are uh oops sorry. Yeah. So we are uh adding the",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2245s",
        "start_time": "2245.719"
    },
    {
        "id": "d2d17fa8",
        "text": "multiplied by the learning rate. Nice. So let's rewrite this in a more compact way. And so we can just like do this. It's the same thing. So we are uh oops sorry. Yeah. So we are uh adding the this color multiplication of like learning rate, um derivatives to weights. And so these are weights and derivatives are two matrices like with the uh with the same dimensions, right? And so we are just like adding them up once we've tweaked the derivatives by dec decide by applying the learning rate",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2251s",
        "start_time": "2251.08"
    },
    {
        "id": "af2ae733",
        "text": "do this. It's the same thing. So we are uh oops sorry. Yeah. So we are uh adding the this color multiplication of like learning rate, um derivatives to weights. And so these are weights and derivatives are two matrices like with the uh with the same dimensions, right? And so we are just like adding them up once we've tweaked the derivatives by dec decide by applying the learning rate good. And so here we have done",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2261s",
        "start_time": "2261.78"
    },
    {
        "id": "5d80b058",
        "text": "this color multiplication of like learning rate, um derivatives to weights. And so these are weights and derivatives are two matrices like with the uh with the same dimensions, right? And so we are just like adding them up once we've tweaked the derivatives by dec decide by applying the learning rate good. And so here we have done uh so we, we, we now have like also gradient descent which is great. So now let's go back to uh like our script here. So we've done back propagation. So the next thing we want to do is we want to apply gradient descent good. So how do we do that? Well, now that we have our uh gradient descent method, this is gonna be super simple to do. So",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2271s",
        "start_time": "2271.85"
    },
    {
        "id": "6806e600",
        "text": "good. And so here we have done uh so we, we, we now have like also gradient descent which is great. So now let's go back to uh like our script here. So we've done back propagation. So the next thing we want to do is we want to apply gradient descent good. So how do we do that? Well, now that we have our uh gradient descent method, this is gonna be super simple to do. So we pass in",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2291s",
        "start_time": "2291.739"
    },
    {
        "id": "fa5ba0d8",
        "text": "uh so we, we, we now have like also gradient descent which is great. So now let's go back to uh like our script here. So we've done back propagation. So the next thing we want to do is we want to apply gradient descent good. So how do we do that? Well, now that we have our uh gradient descent method, this is gonna be super simple to do. So we pass in uh a learning rate. And let's say we want to, to pass in 0.1 for example, as our learning rate good. OK. But uh let's see if gradient descent uh like is working properly. And so for doing that, uh I would come here and I would like to",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2295s",
        "start_time": "2295.659"
    },
    {
        "id": "f94067ff",
        "text": "we pass in uh a learning rate. And let's say we want to, to pass in 0.1 for example, as our learning rate good. OK. But uh let's see if gradient descent uh like is working properly. And so for doing that, uh I would come here and I would like to uh print,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2325s",
        "start_time": "2325.51"
    },
    {
        "id": "d5335b2b",
        "text": "uh a learning rate. And let's say we want to, to pass in 0.1 for example, as our learning rate good. OK. But uh let's see if gradient descent uh like is working properly. And so for doing that, uh I would come here and I would like to uh print, yeah, let's do it here.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2327s",
        "start_time": "2327.35"
    },
    {
        "id": "cf989965",
        "text": "uh print, yeah, let's do it here. So let's do a print. We'll print the",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2347s",
        "start_time": "2347.81"
    },
    {
        "id": "a39d5214",
        "text": "yeah, let's do it here. So let's do a print. We'll print the uh weights.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2350s",
        "start_time": "2350.05"
    },
    {
        "id": "d89787de",
        "text": "So let's do a print. We'll print the uh weights. So we'll, we'll do a w",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2352s",
        "start_time": "2352.07"
    },
    {
        "id": "998c303e",
        "text": "uh weights. So we'll, we'll do a w and I'll go to format and we'll pass in.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2358s",
        "start_time": "2358.01"
    },
    {
        "id": "7a0d8648",
        "text": "So we'll, we'll do a w and I'll go to format and we'll pass in. I, and then here we want actually",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2363s",
        "start_time": "2363.129"
    },
    {
        "id": "20133c76",
        "text": "and I'll go to format and we'll pass in. I, and then here we want actually to pass the oops, sorry. So we ah damn. So I, and here we have the, the weights and so we, we want to pass this in and this is uh yeah, let's call them original.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2369s",
        "start_time": "2369.1"
    },
    {
        "id": "7b686726",
        "text": "I, and then here we want actually to pass the oops, sorry. So we ah damn. So I, and here we have the, the weights and so we, we want to pass this in and this is uh yeah, let's call them original. Um",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2376s",
        "start_time": "2376.159"
    },
    {
        "id": "d680eaa1",
        "text": "to pass the oops, sorry. So we ah damn. So I, and here we have the, the weights and so we, we want to pass this in and this is uh yeah, let's call them original. Um W so these are like the original weights and then we can take this and after. So let's, let's, let's put some new lines here because like this is becoming like a mess, right? So here we, we take the, we retrieve the weights, we print them then uh we retrieve the derivatives, we uh apply like a gradient descent to the weights. And now we have the updated",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2380s",
        "start_time": "2380.919"
    },
    {
        "id": "c4075f1a",
        "text": "Um W so these are like the original weights and then we can take this and after. So let's, let's, let's put some new lines here because like this is becoming like a mess, right? So here we, we take the, we retrieve the weights, we print them then uh we retrieve the derivatives, we uh apply like a gradient descent to the weights. And now we have the updated oops, here we go dated uh weights",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2397s",
        "start_time": "2397.08"
    },
    {
        "id": "2722ddf2",
        "text": "W so these are like the original weights and then we can take this and after. So let's, let's, let's put some new lines here because like this is becoming like a mess, right? So here we, we take the, we retrieve the weights, we print them then uh we retrieve the derivatives, we uh apply like a gradient descent to the weights. And now we have the updated oops, here we go dated uh weights and uh yeah. And so we have like these weights which now should be different. So let's say like if this is working,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2398s",
        "start_time": "2398.879"
    },
    {
        "id": "c51a30e9",
        "text": "oops, here we go dated uh weights and uh yeah. And so we have like these weights which now should be different. So let's say like if this is working, OK. So now I'd say we don't want um",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2426s",
        "start_time": "2426.479"
    },
    {
        "id": "f8661416",
        "text": "and uh yeah. And so we have like these weights which now should be different. So let's say like if this is working, OK. So now I'd say we don't want um to print this because otherwise we're gonna have like a mess. So let's try this and see. OK. So",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2430s",
        "start_time": "2430.469"
    },
    {
        "id": "7fcdceb2",
        "text": "OK. So now I'd say we don't want um to print this because otherwise we're gonna have like a mess. So let's try this and see. OK. So uh we have,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2438s",
        "start_time": "2438.689"
    },
    {
        "id": "a66eeb34",
        "text": "to print this because otherwise we're gonna have like a mess. So let's try this and see. OK. So uh we have, yeah. Right. There's a difference but it's so take like for example this, right? That, that's like the uh the first. So element 00 of like W zero and element 00 of like W zero here, like after we've applied it and as you can see like they are slightly different but the difference like it's quite minimal because like we have like a small learning rate. So if we change this learning rate and we put it like as one, so",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2444s",
        "start_time": "2444.889"
    },
    {
        "id": "edd66587",
        "text": "uh we have, yeah. Right. There's a difference but it's so take like for example this, right? That, that's like the uh the first. So element 00 of like W zero and element 00 of like W zero here, like after we've applied it and as you can see like they are slightly different but the difference like it's quite minimal because like we have like a small learning rate. So if we change this learning rate and we put it like as one, so this should be like quite bigger.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2454s",
        "start_time": "2454.07"
    },
    {
        "id": "22491d12",
        "text": "yeah. Right. There's a difference but it's so take like for example this, right? That, that's like the uh the first. So element 00 of like W zero and element 00 of like W zero here, like after we've applied it and as you can see like they are slightly different but the difference like it's quite minimal because like we have like a small learning rate. So if we change this learning rate and we put it like as one, so this should be like quite bigger. Yeah. So yeah,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2459s",
        "start_time": "2459.08"
    },
    {
        "id": "65d60990",
        "text": "this should be like quite bigger. Yeah. So yeah, you, you can see it from here like w one here like the, the first element here uh like it's uh 0.8 and here",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2489s",
        "start_time": "2489.169"
    },
    {
        "id": "05249e6b",
        "text": "Yeah. So yeah, you, you can see it from here like w one here like the, the first element here uh like it's uh 0.8 and here uh in the updated W one like the first element is 0.76. So basically uh grading the center is working properly and this is great news nice. Uh But now we actually really don't need this like uh at all. Yeah. Yeah, because I mean like it was just like for showing whether like we this was working. So let's remove that nice.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2494s",
        "start_time": "2494.06"
    },
    {
        "id": "2a45f4d5",
        "text": "you, you can see it from here like w one here like the, the first element here uh like it's uh 0.8 and here uh in the updated W one like the first element is 0.76. So basically uh grading the center is working properly and this is great news nice. Uh But now we actually really don't need this like uh at all. Yeah. Yeah, because I mean like it was just like for showing whether like we this was working. So let's remove that nice. So now what's what remains to do here? So we've implemented gradient descent. Now we should implement the train method nice. So back propagate gradient descent and now let's do train.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2497s",
        "start_time": "2497.209"
    },
    {
        "id": "2c951c13",
        "text": "uh in the updated W one like the first element is 0.76. So basically uh grading the center is working properly and this is great news nice. Uh But now we actually really don't need this like uh at all. Yeah. Yeah, because I mean like it was just like for showing whether like we this was working. So let's remove that nice. So now what's what remains to do here? So we've implemented gradient descent. Now we should implement the train method nice. So back propagate gradient descent and now let's do train. So the train method is gonna have",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2507s",
        "start_time": "2507.34"
    },
    {
        "id": "4371942f",
        "text": "So now what's what remains to do here? So we've implemented gradient descent. Now we should implement the train method nice. So back propagate gradient descent and now let's do train. So the train method is gonna have uh oops, there's a mistake here,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2531s",
        "start_time": "2531.989"
    },
    {
        "id": "f0aba94a",
        "text": "So the train method is gonna have uh oops, there's a mistake here, are you?",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2548s",
        "start_time": "2548.679"
    },
    {
        "id": "b0b810bc",
        "text": "uh oops, there's a mistake here, are you? Yeah, here we go.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2555s",
        "start_time": "2555.239"
    },
    {
        "id": "15021741",
        "text": "are you? Yeah, here we go. Uh The train method is gonna uh have a bunch of different arguments. So first of all, we want some inputs, then uh we want uh targets",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2558s",
        "start_time": "2558.05"
    },
    {
        "id": "b95c371b",
        "text": "Yeah, here we go. Uh The train method is gonna uh have a bunch of different arguments. So first of all, we want some inputs, then uh we want uh targets and uh these inputs and targets are our training set uh which uh like our X is like in Y basically. And then we want uh epics and I'll explain what an epic is in a second. And then we want the learning rate, right?",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2559s",
        "start_time": "2559.27"
    },
    {
        "id": "0a37e51d",
        "text": "Uh The train method is gonna uh have a bunch of different arguments. So first of all, we want some inputs, then uh we want uh targets and uh these inputs and targets are our training set uh which uh like our X is like in Y basically. And then we want uh epics and I'll explain what an epic is in a second. And then we want the learning rate, right? Good. OK. So what should we do for training? Well, if you guys remember? So uh we, we pass all the inputs like one by one to the network, we fit it and then the network does some uh forward propagation and then back propagation. Uh But then once we've passed all of the um elements, all of the samples like in the, in the inputs",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2560s",
        "start_time": "2560.639"
    },
    {
        "id": "7fcee7b0",
        "text": "and uh these inputs and targets are our training set uh which uh like our X is like in Y basically. And then we want uh epics and I'll explain what an epic is in a second. And then we want the learning rate, right? Good. OK. So what should we do for training? Well, if you guys remember? So uh we, we pass all the inputs like one by one to the network, we fit it and then the network does some uh forward propagation and then back propagation. Uh But then once we've passed all of the um elements, all of the samples like in the, in the inputs uh in the training set, we've finished an epoch. So the number of epics tells us basically how many times we want to feed the whole data set to uh the uh to the neural network with the idea that the more times we do this and hopefully like the more like the network is going to be able to make better predictions. So,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2575s",
        "start_time": "2575.239"
    },
    {
        "id": "cd787404",
        "text": "Good. OK. So what should we do for training? Well, if you guys remember? So uh we, we pass all the inputs like one by one to the network, we fit it and then the network does some uh forward propagation and then back propagation. Uh But then once we've passed all of the um elements, all of the samples like in the, in the inputs uh in the training set, we've finished an epoch. So the number of epics tells us basically how many times we want to feed the whole data set to uh the uh to the neural network with the idea that the more times we do this and hopefully like the more like the network is going to be able to make better predictions. So, uh basically, what we need to do is like uh go through all the, the Epics and so look through the number of epics. And so, so let's say for i in a range",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2593s",
        "start_time": "2593.479"
    },
    {
        "id": "b122f36a",
        "text": "uh in the training set, we've finished an epoch. So the number of epics tells us basically how many times we want to feed the whole data set to uh the uh to the neural network with the idea that the more times we do this and hopefully like the more like the network is going to be able to make better predictions. So, uh basically, what we need to do is like uh go through all the, the Epics and so look through the number of epics. And so, so let's say for i in a range Epics",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2621s",
        "start_time": "2621.489"
    },
    {
        "id": "09d4a055",
        "text": "uh basically, what we need to do is like uh go through all the, the Epics and so look through the number of epics. And so, so let's say for i in a range Epics And so here",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2646s",
        "start_time": "2646.679"
    },
    {
        "id": "cd5351fb",
        "text": "Epics And so here we should do",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2660s",
        "start_time": "2660.6"
    },
    {
        "id": "985734ad",
        "text": "And so here we should do uh so we should do really like a bunch of different things. So first of all, we should take",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2662s",
        "start_time": "2662.989"
    },
    {
        "id": "2b6b9204",
        "text": "we should do uh so we should do really like a bunch of different things. So first of all, we should take the,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2666s",
        "start_time": "2666.09"
    },
    {
        "id": "7b89a832",
        "text": "uh so we should do really like a bunch of different things. So first of all, we should take the, so we should go through like all the inputs and uh the uh the uh the targets are like one by one. So how are we gonna do this? Well, uh there's like a nice trick we can use here and we could say,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2668s",
        "start_time": "2668.729"
    },
    {
        "id": "4a57d098",
        "text": "the, so we should go through like all the inputs and uh the uh the uh the targets are like one by one. So how are we gonna do this? Well, uh there's like a nice trick we can use here and we could say, uh yell at me just like write this and I'll explain what this is in a second. So for J input target in",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2677s",
        "start_time": "2677.5"
    },
    {
        "id": "a7b9338c",
        "text": "so we should go through like all the inputs and uh the uh the uh the targets are like one by one. So how are we gonna do this? Well, uh there's like a nice trick we can use here and we could say, uh yell at me just like write this and I'll explain what this is in a second. So for J input target in and now we do an a numerate and then we do a zip over here and we pass in the inputs and we pass in the targets. Cool.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2679s",
        "start_time": "2679.699"
    },
    {
        "id": "d681f531",
        "text": "uh yell at me just like write this and I'll explain what this is in a second. So for J input target in and now we do an a numerate and then we do a zip over here and we pass in the inputs and we pass in the targets. Cool. So this is like a very compact way of like getting uh like",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2695s",
        "start_time": "2695.3"
    },
    {
        "id": "8310d440",
        "text": "and now we do an a numerate and then we do a zip over here and we pass in the inputs and we pass in the targets. Cool. So this is like a very compact way of like getting uh like inputs targets one by one and, and, and it's like this input and target and also getting like the index that we are unpacking. So zip unpacks like this two different lists, inputs and targets and give us like elements one by one for input and for targets. And then if we apply a numeration on top of that, we both get these the values themselves and uh the index that we are unpacking good. So",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2703s",
        "start_time": "2703.149"
    },
    {
        "id": "c1f20b93",
        "text": "So this is like a very compact way of like getting uh like inputs targets one by one and, and, and it's like this input and target and also getting like the index that we are unpacking. So zip unpacks like this two different lists, inputs and targets and give us like elements one by one for input and for targets. And then if we apply a numeration on top of that, we both get these the values themselves and uh the index that we are unpacking good. So yeah, this is like a nice trick. Uh Cool. So now what should we do? Well, uh we've partially done a bunch of these things already. So uh let's take these guys here, right? So, and we'll uh move them",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2715s",
        "start_time": "2715.939"
    },
    {
        "id": "5eb38169",
        "text": "inputs targets one by one and, and, and it's like this input and target and also getting like the index that we are unpacking. So zip unpacks like this two different lists, inputs and targets and give us like elements one by one for input and for targets. And then if we apply a numeration on top of that, we both get these the values themselves and uh the index that we are unpacking good. So yeah, this is like a nice trick. Uh Cool. So now what should we do? Well, uh we've partially done a bunch of these things already. So uh let's take these guys here, right? So, and we'll uh move them here",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2722s",
        "start_time": "2722.389"
    },
    {
        "id": "9d622adf",
        "text": "yeah, this is like a nice trick. Uh Cool. So now what should we do? Well, uh we've partially done a bunch of these things already. So uh let's take these guys here, right? So, and we'll uh move them here say",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2750s",
        "start_time": "2750.75"
    },
    {
        "id": "be0f8f9f",
        "text": "here say what do we want to do? Well,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2768s",
        "start_time": "2768.02"
    },
    {
        "id": "144fa96b",
        "text": "say what do we want to do? Well, first thing we want to apply some forward propagation",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2769s",
        "start_time": "2769.51"
    },
    {
        "id": "e8b37196",
        "text": "what do we want to do? Well, first thing we want to apply some forward propagation but this is not gonna be M LP but it, this is gonna be a self. So we do forward propagate on the input, then we calculate the error and uh this is gonna be the target minus the output and then we apply some back propagation. But this again is gonna be like a self back propagate and we pass in uh the error and then we apply gradient, the sound.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2770s",
        "start_time": "2770.679"
    },
    {
        "id": "564410b8",
        "text": "first thing we want to apply some forward propagation but this is not gonna be M LP but it, this is gonna be a self. So we do forward propagate on the input, then we calculate the error and uh this is gonna be the target minus the output and then we apply some back propagation. But this again is gonna be like a self back propagate and we pass in uh the error and then we apply gradient, the sound. Uh here we go",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2773s",
        "start_time": "2773.81"
    },
    {
        "id": "906d6621",
        "text": "but this is not gonna be M LP but it, this is gonna be a self. So we do forward propagate on the input, then we calculate the error and uh this is gonna be the target minus the output and then we apply some back propagation. But this again is gonna be like a self back propagate and we pass in uh the error and then we apply gradient, the sound. Uh here we go change M LP for itself and the learning rate. Uh Yeah, we already have it here.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2779s",
        "start_time": "2779.29"
    },
    {
        "id": "21551ec4",
        "text": "Uh here we go change M LP for itself and the learning rate. Uh Yeah, we already have it here. Oh By the way, I noticed there's a mistake over here. So it's not uh for I in range apex but is in the length.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2806s",
        "start_time": "2806.86"
    },
    {
        "id": "115ff743",
        "text": "change M LP for itself and the learning rate. Uh Yeah, we already have it here. Oh By the way, I noticed there's a mistake over here. So it's not uh for I in range apex but is in the length. Oh No, sorry, I was right. I thought like for a, for a second that apex was a, was a list. It's just an integer. So it's fine, good. OK. Uh cool. So we have uh grade in the sand and we've uh applied uh grade in the sand. So",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2809s",
        "start_time": "2809.679"
    },
    {
        "id": "876af485",
        "text": "Oh By the way, I noticed there's a mistake over here. So it's not uh for I in range apex but is in the length. Oh No, sorry, I was right. I thought like for a, for a second that apex was a, was a list. It's just an integer. So it's fine, good. OK. Uh cool. So we have uh grade in the sand and we've uh applied uh grade in the sand. So now one last thing that we want to do is to report",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2818s",
        "start_time": "2818.419"
    },
    {
        "id": "a29bbf90",
        "text": "Oh No, sorry, I was right. I thought like for a, for a second that apex was a, was a list. It's just an integer. So it's fine, good. OK. Uh cool. So we have uh grade in the sand and we've uh applied uh grade in the sand. So now one last thing that we want to do is to report the error for each epoch so that we can see whether we are uh improving. So how do we do that? Well, first of all, we want to um initialize some error uh variable over here and we'll initialize that obviously, that's a zero. And then at the end of each um",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2828s",
        "start_time": "2828.75"
    },
    {
        "id": "3c2904d3",
        "text": "now one last thing that we want to do is to report the error for each epoch so that we can see whether we are uh improving. So how do we do that? Well, first of all, we want to um initialize some error uh variable over here and we'll initialize that obviously, that's a zero. And then at the end of each um like a training session like for, for uh for each input, we are uh gonna calculate this some error and we'll add to some error. What are we gonna add? So we're gonna add",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2848s",
        "start_time": "2848.36"
    },
    {
        "id": "b543f42d",
        "text": "the error for each epoch so that we can see whether we are uh improving. So how do we do that? Well, first of all, we want to um initialize some error uh variable over here and we'll initialize that obviously, that's a zero. And then at the end of each um like a training session like for, for uh for each input, we are uh gonna calculate this some error and we'll add to some error. What are we gonna add? So we're gonna add self dot",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2855s",
        "start_time": "2855.61"
    },
    {
        "id": "6493313d",
        "text": "like a training session like for, for uh for each input, we are uh gonna calculate this some error and we'll add to some error. What are we gonna add? So we're gonna add self dot MS E",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2877s",
        "start_time": "2877.77"
    },
    {
        "id": "31b15f47",
        "text": "self dot MS E and uh we'll pass the target",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2894s",
        "start_time": "2894.419"
    },
    {
        "id": "126cdec4",
        "text": "MS E and uh we'll pass the target and the",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2898s",
        "start_time": "2898.199"
    },
    {
        "id": "ea585352",
        "text": "and uh we'll pass the target and the output",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2900s",
        "start_time": "2900.239"
    },
    {
        "id": "8c9376b7",
        "text": "and the output good. So what's this, MS E here? So this is the M squared uh error, right? And so we don't have this uh function, this method already. And so we need to build it. So let's implement it down here. So we'll do the MS E self and we'll pass in target",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2905s",
        "start_time": "2905.33"
    },
    {
        "id": "606e99fe",
        "text": "output good. So what's this, MS E here? So this is the M squared uh error, right? And so we don't have this uh function, this method already. And so we need to build it. So let's implement it down here. So we'll do the MS E self and we'll pass in target and the output. And so, so it's not MS R, it's MS E so M squared error. So, and what is this? So how do we calculate this? Well, this is basically the average of the, the squared error, right? And so we can use a native um uh method from NP it's called average super handy. And we'll",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2907s",
        "start_time": "2907.37"
    },
    {
        "id": "cd7577dc",
        "text": "good. So what's this, MS E here? So this is the M squared uh error, right? And so we don't have this uh function, this method already. And so we need to build it. So let's implement it down here. So we'll do the MS E self and we'll pass in target and the output. And so, so it's not MS R, it's MS E so M squared error. So, and what is this? So how do we calculate this? Well, this is basically the average of the, the squared error, right? And so we can use a native um uh method from NP it's called average super handy. And we'll basically rewrite this uh like this. So we'll do the average of the target minus the output and we want to square this. So we'll do this, right? And so this is the",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2908s",
        "start_time": "2908.86"
    },
    {
        "id": "5f811e68",
        "text": "and the output. And so, so it's not MS R, it's MS E so M squared error. So, and what is this? So how do we calculate this? Well, this is basically the average of the, the squared error, right? And so we can use a native um uh method from NP it's called average super handy. And we'll basically rewrite this uh like this. So we'll do the average of the target minus the output and we want to square this. So we'll do this, right? And so this is the or",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2931s",
        "start_time": "2931.629"
    },
    {
        "id": "69ee0e2c",
        "text": "basically rewrite this uh like this. So we'll do the average of the target minus the output and we want to square this. So we'll do this, right? And so this is the or uh means squared error",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2958s",
        "start_time": "2958.179"
    },
    {
        "id": "d8a4e944",
        "text": "or uh means squared error nice. So now we have a, an error that's accumulating like at every step that we take like in our training and, and we want to report it like at the end of an epoch,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2975s",
        "start_time": "2975.51"
    },
    {
        "id": "09bce26b",
        "text": "uh means squared error nice. So now we have a, an error that's accumulating like at every step that we take like in our training and, and we want to report it like at the end of an epoch, right? And so how do we uh do that? Right. So we'll",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2977s",
        "start_time": "2977.06"
    },
    {
        "id": "940172cf",
        "text": "nice. So now we have a, an error that's accumulating like at every step that we take like in our training and, and we want to report it like at the end of an epoch, right? And so how do we uh do that? Right. So we'll um we'll do that",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2979s",
        "start_time": "2979.31"
    },
    {
        "id": "e633fa88",
        "text": "right? And so how do we uh do that? Right. So we'll um we'll do that by",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=2992s",
        "start_time": "2992.6"
    },
    {
        "id": "3de692f8",
        "text": "um we'll do that by uh yes. So we'll just like do a print over here",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3001s",
        "start_time": "3001.649"
    },
    {
        "id": "d5849575",
        "text": "by uh yes. So we'll just like do a print over here and uh will write uh error",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3006s",
        "start_time": "3006.08"
    },
    {
        "id": "d6b37e0e",
        "text": "uh yes. So we'll just like do a print over here and uh will write uh error and we'll say error is equal to something at epoch",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3008s",
        "start_time": "3008.199"
    },
    {
        "id": "be3e491c",
        "text": "and uh will write uh error and we'll say error is equal to something at epoch and we'll have the",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3014s",
        "start_time": "3014.459"
    },
    {
        "id": "dde4f81f",
        "text": "and we'll say error is equal to something at epoch and we'll have the epoch over here.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3023s",
        "start_time": "3023.0"
    },
    {
        "id": "226ad69b",
        "text": "and we'll have the epoch over here. Cool. And so we'll do a format and uh we'll pass in for the error, some",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3029s",
        "start_time": "3029.949"
    },
    {
        "id": "27a8aec6",
        "text": "epoch over here. Cool. And so we'll do a format and uh we'll pass in for the error, some error",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3033s",
        "start_time": "3033.79"
    },
    {
        "id": "2c8f222e",
        "text": "Cool. And so we'll do a format and uh we'll pass in for the error, some error uh divided uh by the",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3036s",
        "start_time": "3036.449"
    },
    {
        "id": "0fe9f48d",
        "text": "error uh divided uh by the length of the",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3046s",
        "start_time": "3046.75"
    },
    {
        "id": "1428878f",
        "text": "uh divided uh by the length of the inputs,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3048s",
        "start_time": "3048.79"
    },
    {
        "id": "a1631755",
        "text": "length of the inputs, right? Because this way, we are basically like uh normalizing that. And um what we also want to do is we want to pass",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3053s",
        "start_time": "3053.419"
    },
    {
        "id": "d0ed5b75",
        "text": "inputs, right? Because this way, we are basically like uh normalizing that. And um what we also want to do is we want to pass um the number of epochs. So in this case is I, right? So let me just double check if it's all good over here. So we have this format. Yeah, this is not working.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3057s",
        "start_time": "3057.409"
    },
    {
        "id": "74c31d23",
        "text": "right? Because this way, we are basically like uh normalizing that. And um what we also want to do is we want to pass um the number of epochs. So in this case is I, right? So let me just double check if it's all good over here. So we have this format. Yeah, this is not working. OK. So yeah, so we have the first argument. That's this one here and then we have",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3059s",
        "start_time": "3059.84"
    },
    {
        "id": "d26c5088",
        "text": "um the number of epochs. So in this case is I, right? So let me just double check if it's all good over here. So we have this format. Yeah, this is not working. OK. So yeah, so we have the first argument. That's this one here and then we have I",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3074s",
        "start_time": "3074.36"
    },
    {
        "id": "b0fa9759",
        "text": "OK. So yeah, so we have the first argument. That's this one here and then we have I and this yeah, closes the format which yeah, so this should be fine now.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3093s",
        "start_time": "3093.669"
    },
    {
        "id": "acc9f80f",
        "text": "I and this yeah, closes the format which yeah, so this should be fine now. Uh Good.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3100s",
        "start_time": "3100.03"
    },
    {
        "id": "92a40391",
        "text": "and this yeah, closes the format which yeah, so this should be fine now. Uh Good. OK. So now I think we have all the elements uh if I'm not uh",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3101s",
        "start_time": "3101.909"
    },
    {
        "id": "de2ef093",
        "text": "Uh Good. OK. So now I think we have all the elements uh if I'm not uh if I'm mistaken, we have all the elements in place for doing a run",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3109s",
        "start_time": "3109.06"
    },
    {
        "id": "dcdf3ec6",
        "text": "OK. So now I think we have all the elements uh if I'm not uh if I'm mistaken, we have all the elements in place for doing a run of our um uh neural network good. So, but before doing that, I just want to, to, to double check of things because like, I did this like, I did like this fancy thing here, but I'm not using like j uh like anywhere. So I don't really think like we're gonna need uh like this J uh Yeah. Yeah, I didn't see a point here. So, yeah,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3110s",
        "start_time": "3110.679"
    },
    {
        "id": "856ff9cc",
        "text": "if I'm mistaken, we have all the elements in place for doing a run of our um uh neural network good. So, but before doing that, I just want to, to, to double check of things because like, I did this like, I did like this fancy thing here, but I'm not using like j uh like anywhere. So I don't really think like we're gonna need uh like this J uh Yeah. Yeah, I didn't see a point here. So, yeah, well, at least like you've learned a trick, but it's not really needed. So we'll just like simplify this and we'll just drop this and numerate um like that, right? So now, now this uh should work properly good. OK. So, uh now",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3117s",
        "start_time": "3117.689"
    },
    {
        "id": "827b4c7d",
        "text": "of our um uh neural network good. So, but before doing that, I just want to, to, to double check of things because like, I did this like, I did like this fancy thing here, but I'm not using like j uh like anywhere. So I don't really think like we're gonna need uh like this J uh Yeah. Yeah, I didn't see a point here. So, yeah, well, at least like you've learned a trick, but it's not really needed. So we'll just like simplify this and we'll just drop this and numerate um like that, right? So now, now this uh should work properly good. OK. So, uh now uh let's go back to our tasks. So we, we basically did all of these things here. So now we want to train our nets with some dummy uh data set and then make some predictions. OK? So let's go back here. So now we are back like in the, in the scripts. OK. So we've already created uh an M LP. And uh now we want to",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3123s",
        "start_time": "3123.37"
    },
    {
        "id": "03b82d20",
        "text": "well, at least like you've learned a trick, but it's not really needed. So we'll just like simplify this and we'll just drop this and numerate um like that, right? So now, now this uh should work properly good. OK. So, uh now uh let's go back to our tasks. So we, we basically did all of these things here. So now we want to train our nets with some dummy uh data set and then make some predictions. OK? So let's go back here. So now we are back like in the, in the scripts. OK. So we've already created uh an M LP. And uh now we want to uh train",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3151s",
        "start_time": "3151.209"
    },
    {
        "id": "eff9377b",
        "text": "uh let's go back to our tasks. So we, we basically did all of these things here. So now we want to train our nets with some dummy uh data set and then make some predictions. OK? So let's go back here. So now we are back like in the, in the scripts. OK. So we've already created uh an M LP. And uh now we want to uh train uh our M LP.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3170s",
        "start_time": "3170.469"
    },
    {
        "id": "2ff836aa",
        "text": "uh train uh our M LP. And how do we do that? Well, we do M LP dot train.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3196s",
        "start_time": "3196.11"
    },
    {
        "id": "f9308188",
        "text": "uh our M LP. And how do we do that? Well, we do M LP dot train. Uh we need to pass in the inputs, the targets, then uh we need to pass the number of epics, let's say 50 for example, and the learning rate, let's say 0.1. And uh yeah, and we need some dummy data. So for the inputs and uh for uh the targets. Now,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3199s",
        "start_time": "3199.979"
    },
    {
        "id": "2965b26d",
        "text": "And how do we do that? Well, we do M LP dot train. Uh we need to pass in the inputs, the targets, then uh we need to pass the number of epics, let's say 50 for example, and the learning rate, let's say 0.1. And uh yeah, and we need some dummy data. So for the inputs and uh for uh the targets. Now, I want to, as I mentioned earlier, I want to",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3202s",
        "start_time": "3202.629"
    },
    {
        "id": "9e0af809",
        "text": "Uh we need to pass in the inputs, the targets, then uh we need to pass the number of epics, let's say 50 for example, and the learning rate, let's say 0.1. And uh yeah, and we need some dummy data. So for the inputs and uh for uh the targets. Now, I want to, as I mentioned earlier, I want to um train our network so that it will be able to uh to compute uh the sum operation. So I'm gonna just like copy paste a um radiation like a data set like for this. And so I, I'm not gonna like explain everything here because like this is like not the point. Uh But uh so, first of all, like we need this random function",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3208s",
        "start_time": "3208.51"
    },
    {
        "id": "c4712014",
        "text": "I want to, as I mentioned earlier, I want to um train our network so that it will be able to uh to compute uh the sum operation. So I'm gonna just like copy paste a um radiation like a data set like for this. And so I, I'm not gonna like explain everything here because like this is like not the point. Uh But uh so, first of all, like we need this random function and so we need to import a random here otherwise it's not gonna uh work. So we'd say from uh random import uh random. And so we have that now down here.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3235s",
        "start_time": "3235.28"
    },
    {
        "id": "1115e09e",
        "text": "um train our network so that it will be able to uh to compute uh the sum operation. So I'm gonna just like copy paste a um radiation like a data set like for this. And so I, I'm not gonna like explain everything here because like this is like not the point. Uh But uh so, first of all, like we need this random function and so we need to import a random here otherwise it's not gonna uh work. So we'd say from uh random import uh random. And so we have that now down here. Uh Yeah, which is good.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3240s",
        "start_time": "3240.199"
    },
    {
        "id": "b65243eb",
        "text": "and so we need to import a random here otherwise it's not gonna uh work. So we'd say from uh random import uh random. And so we have that now down here. Uh Yeah, which is good. OK. So now we should have, but uh let's call this inputs and let's call this like uh targets, right? OK. So what's the point of this? Um",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3266s",
        "start_time": "3266.55"
    },
    {
        "id": "b6615c2a",
        "text": "Uh Yeah, which is good. OK. So now we should have, but uh let's call this inputs and let's call this like uh targets, right? OK. So what's the point of this? Um Yeah, this fancy like list comprehensions like we had a raise and things like that. Well, basically this is going to be an array",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3281s",
        "start_time": "3281.379"
    },
    {
        "id": "9b8305a9",
        "text": "OK. So now we should have, but uh let's call this inputs and let's call this like uh targets, right? OK. So what's the point of this? Um Yeah, this fancy like list comprehensions like we had a raise and things like that. Well, basically this is going to be an array uh where we have uh so something like this. So this is gonna be like a nr A uh where we have",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3283s",
        "start_time": "3283.379"
    },
    {
        "id": "6d9ad658",
        "text": "Yeah, this fancy like list comprehensions like we had a raise and things like that. Well, basically this is going to be an array uh where we have uh so something like this. So this is gonna be like a nr A uh where we have this type of structure here. So say like 0.10 0.2 and then we have another",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3295s",
        "start_time": "3295.8"
    },
    {
        "id": "c80e3ae4",
        "text": "uh where we have uh so something like this. So this is gonna be like a nr A uh where we have this type of structure here. So say like 0.10 0.2 and then we have another are we here? And so these are like each of these guys in here is gonna be a sample that we pass to forward propagation, right? And uh then we have the targets and the targets are,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3305s",
        "start_time": "3305.219"
    },
    {
        "id": "8ce7ed03",
        "text": "this type of structure here. So say like 0.10 0.2 and then we have another are we here? And so these are like each of these guys in here is gonna be a sample that we pass to forward propagation, right? And uh then we have the targets and the targets are, it's similar to this, but",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3319s",
        "start_time": "3319.07"
    },
    {
        "id": "e7b8b6ba",
        "text": "are we here? And so these are like each of these guys in here is gonna be a sample that we pass to forward propagation, right? And uh then we have the targets and the targets are, it's similar to this, but it's just like the,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3329s",
        "start_time": "3329.129"
    },
    {
        "id": "ecafb719",
        "text": "it's similar to this, but it's just like the, the sum over here. So instead of having like two values, you're just gonna have one which is zero point point three in this case. And this is gonna be uh 0.7",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3345s",
        "start_time": "3345.82"
    },
    {
        "id": "6412c7ae",
        "text": "it's just like the, the sum over here. So instead of having like two values, you're just gonna have one which is zero point point three in this case. And this is gonna be uh 0.7 uh right, this is items is not correct. So we'll just need to move it from inputs. And right, so this is fine now good. So now if everything is correct now we should be able to train our multi-layered perception from scratch. Let's see if it works.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3348s",
        "start_time": "3348.82"
    },
    {
        "id": "de4315d2",
        "text": "the sum over here. So instead of having like two values, you're just gonna have one which is zero point point three in this case. And this is gonna be uh 0.7 uh right, this is items is not correct. So we'll just need to move it from inputs. And right, so this is fine now good. So now if everything is correct now we should be able to train our multi-layered perception from scratch. Let's see if it works. Whoa This is working. And that's fantastic because we have also a very nice record over here. So we started with this error at",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3350s",
        "start_time": "3350.919"
    },
    {
        "id": "41bff906",
        "text": "uh right, this is items is not correct. So we'll just need to move it from inputs. And right, so this is fine now good. So now if everything is correct now we should be able to train our multi-layered perception from scratch. Let's see if it works. Whoa This is working. And that's fantastic because we have also a very nice record over here. So we started with this error at epoch uh zero.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3361s",
        "start_time": "3361.909"
    },
    {
        "id": "1fc70b76",
        "text": "Whoa This is working. And that's fantastic because we have also a very nice record over here. So we started with this error at epoch uh zero. And then all the way through, we went down, down, down at each epoch until we reached this",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3383s",
        "start_time": "3383.33"
    },
    {
        "id": "e44b8610",
        "text": "epoch uh zero. And then all the way through, we went down, down, down at each epoch until we reached this uh error over here. So as you see, the training is working because the error is going down. And so the the network is slowly learning to, to do something very simple, which is like the some operation someone could say, well, this is really like overkill to do like some, yeah, some but I'm in. Yeah, that's what it is, right. OK. So now we've uh we've implemented like",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3397s",
        "start_time": "3397.11"
    },
    {
        "id": "bf15c88b",
        "text": "And then all the way through, we went down, down, down at each epoch until we reached this uh error over here. So as you see, the training is working because the error is going down. And so the the network is slowly learning to, to do something very simple, which is like the some operation someone could say, well, this is really like overkill to do like some, yeah, some but I'm in. Yeah, that's what it is, right. OK. So now we've uh we've implemented like all back propagation grid and descent. We have a, an amazing mop. So now what remains to do like the last thing that we said we would do is make some predictions, right? OK. So how do we do that? So, yeah, this is uh again, uh quite simple. So yeah, let's create uh create uh dummy data.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3399s",
        "start_time": "3399.419"
    },
    {
        "id": "127dfe87",
        "text": "uh error over here. So as you see, the training is working because the error is going down. And so the the network is slowly learning to, to do something very simple, which is like the some operation someone could say, well, this is really like overkill to do like some, yeah, some but I'm in. Yeah, that's what it is, right. OK. So now we've uh we've implemented like all back propagation grid and descent. We have a, an amazing mop. So now what remains to do like the last thing that we said we would do is make some predictions, right? OK. So how do we do that? So, yeah, this is uh again, uh quite simple. So yeah, let's create uh create uh dummy data. And this time, let's call this input",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3408s",
        "start_time": "3408.34"
    },
    {
        "id": "6430b8a1",
        "text": "all back propagation grid and descent. We have a, an amazing mop. So now what remains to do like the last thing that we said we would do is make some predictions, right? OK. So how do we do that? So, yeah, this is uh again, uh quite simple. So yeah, let's create uh create uh dummy data. And this time, let's call this input and we do NP dot uh array. And here we want to pass in",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3435s",
        "start_time": "3435.57"
    },
    {
        "id": "e6e97f78",
        "text": "And this time, let's call this input and we do NP dot uh array. And here we want to pass in uh let's say 0.3 and 0.1",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3462s",
        "start_time": "3462.53"
    },
    {
        "id": "fc1774b0",
        "text": "and we do NP dot uh array. And here we want to pass in uh let's say 0.3 and 0.1 good. And now we want our targets and we know that our targets should be the sum of those two numbers. So 0.4 right? And so now what we need to do is M LP,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3467s",
        "start_time": "3467.0"
    },
    {
        "id": "e90ed1f5",
        "text": "uh let's say 0.3 and 0.1 good. And now we want our targets and we know that our targets should be the sum of those two numbers. So 0.4 right? And so now what we need to do is M LP, tell it",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3475s",
        "start_time": "3475.09"
    },
    {
        "id": "d40d715d",
        "text": "good. And now we want our targets and we know that our targets should be the sum of those two numbers. So 0.4 right? And so now what we need to do is M LP, tell it mop dot forward propagate and then we want to pass in the input and then we expect some output, right?",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3480s",
        "start_time": "3480.399"
    },
    {
        "id": "16aa8f10",
        "text": "tell it mop dot forward propagate and then we want to pass in the input and then we expect some output, right? So the idea like the, the, the, the whole like train like a for here is we have like our uh training data set, we built like our mop, we train our M LP and now we create some Demi data and we pass that in uh forward propagate so that we'll get uh like a prediction out there. So let's see how this prediction is doing.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3498s",
        "start_time": "3498.419"
    },
    {
        "id": "b9cba8e1",
        "text": "mop dot forward propagate and then we want to pass in the input and then we expect some output, right? So the idea like the, the, the, the whole like train like a for here is we have like our uh training data set, we built like our mop, we train our M LP and now we create some Demi data and we pass that in uh forward propagate so that we'll get uh like a prediction out there. So let's see how this prediction is doing. And so meantime, we'll do like just a print to give us a couple of prints to, to give us like a couple of new lines and then we'll do print and we'll say",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3499s",
        "start_time": "3499.969"
    },
    {
        "id": "c75b8f30",
        "text": "So the idea like the, the, the, the whole like train like a for here is we have like our uh training data set, we built like our mop, we train our M LP and now we create some Demi data and we pass that in uh forward propagate so that we'll get uh like a prediction out there. So let's see how this prediction is doing. And so meantime, we'll do like just a print to give us a couple of prints to, to give us like a couple of new lines and then we'll do print and we'll say um",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3512s",
        "start_time": "3512.179"
    },
    {
        "id": "0a8eb076",
        "text": "And so meantime, we'll do like just a print to give us a couple of prints to, to give us like a couple of new lines and then we'll do print and we'll say um so let's say",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3537s",
        "start_time": "3537.51"
    },
    {
        "id": "8fb81167",
        "text": "um so let's say this. So let's say our network",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3550s",
        "start_time": "3550.129"
    },
    {
        "id": "4f49a14c",
        "text": "so let's say this. So let's say our network the leaves.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3552s",
        "start_time": "3552.36"
    },
    {
        "id": "85ba1f62",
        "text": "this. So let's say our network the leaves. That's",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3555s",
        "start_time": "3555.28"
    },
    {
        "id": "23bad519",
        "text": "the leaves. That's this plus this is",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3561s",
        "start_time": "3561.449"
    },
    {
        "id": "b549092c",
        "text": "That's this plus this is equal",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3563s",
        "start_time": "3563.709"
    },
    {
        "id": "91232cf1",
        "text": "this plus this is equal equal to,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3566s",
        "start_time": "3566.33"
    },
    {
        "id": "48b53d9c",
        "text": "equal equal to, it's",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3570s",
        "start_time": "3570.169"
    },
    {
        "id": "57c74d6d",
        "text": "equal to, it's uh this right now, we need to pass all of this information in. So uh our beliefs that input,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3573s",
        "start_time": "3573.479"
    },
    {
        "id": "9cab4576",
        "text": "it's uh this right now, we need to pass all of this information in. So uh our beliefs that input, so this is input uh zero, this is input uh one. And finally, this is uh our target, right?",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3577s",
        "start_time": "3577.409"
    },
    {
        "id": "389ac80b",
        "text": "uh this right now, we need to pass all of this information in. So uh our beliefs that input, so this is input uh zero, this is input uh one. And finally, this is uh our target, right? Uh Well, no, it's not our target. Sorry, it's our output.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3578s",
        "start_time": "3578.79"
    },
    {
        "id": "73c95892",
        "text": "so this is input uh zero, this is input uh one. And finally, this is uh our target, right? Uh Well, no, it's not our target. Sorry, it's our output. Cool, I'll put",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3590s",
        "start_time": "3590.1"
    },
    {
        "id": "4e8bd78a",
        "text": "Uh Well, no, it's not our target. Sorry, it's our output. Cool, I'll put calculation and zero, right? OK. So let's run this and see if our network is gonna be able uh to uh compute this, right?",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3604s",
        "start_time": "3604.199"
    },
    {
        "id": "da6584eb",
        "text": "Cool, I'll put calculation and zero, right? OK. So let's run this and see if our network is gonna be able uh to uh compute this, right? And um right. So let's do that. And",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3609s",
        "start_time": "3609.639"
    },
    {
        "id": "dccdb13f",
        "text": "calculation and zero, right? OK. So let's run this and see if our network is gonna be able uh to uh compute this, right? And um right. So let's do that. And let's see.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3612s",
        "start_time": "3612.459"
    },
    {
        "id": "4acf67ee",
        "text": "And um right. So let's do that. And let's see. Nice. Super good. So we, we have it here. Nice. So our network believes that 0.3 plus 0.1 is equal to 0.3996. Nice. So this is really close to our target, which is",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3625s",
        "start_time": "3625.61"
    },
    {
        "id": "11654c4e",
        "text": "let's see. Nice. Super good. So we, we have it here. Nice. So our network believes that 0.3 plus 0.1 is equal to 0.3996. Nice. So this is really close to our target, which is uh no 0.4 right? So this is like quite good actually. So we, we made it, we trained our network, we have this like network which is an absolute overkill for calculating like the same operation. But yeah, we made it. But apart from like the the toy application, I think like what we",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3633s",
        "start_time": "3633.35"
    },
    {
        "id": "5ddbafbd",
        "text": "Nice. Super good. So we, we have it here. Nice. So our network believes that 0.3 plus 0.1 is equal to 0.3996. Nice. So this is really close to our target, which is uh no 0.4 right? So this is like quite good actually. So we, we made it, we trained our network, we have this like network which is an absolute overkill for calculating like the same operation. But yeah, we made it. But apart from like the the toy application, I think like what we made it here like it's quite something because we made to basically build a whole neural network, fit forward neural network, multi layer perception from scratch. And now we have all of the different elements to it. We have forward propagation,",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3635s",
        "start_time": "3635.379"
    },
    {
        "id": "996fef53",
        "text": "uh no 0.4 right? So this is like quite good actually. So we, we made it, we trained our network, we have this like network which is an absolute overkill for calculating like the same operation. But yeah, we made it. But apart from like the the toy application, I think like what we made it here like it's quite something because we made to basically build a whole neural network, fit forward neural network, multi layer perception from scratch. And now we have all of the different elements to it. We have forward propagation, we have back propagation, we have gradient descent, we know how we can train it uh everything like it's super modular because you can put like as many uh layers uh in the network as you want and you can specify as many like neurons as you want like, so that's like also like really nice. And so yeah, I think like we should just like congratulate ourselves because I guess like we know way more than most people",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3654s",
        "start_time": "3654.399"
    },
    {
        "id": "dccdf228",
        "text": "made it here like it's quite something because we made to basically build a whole neural network, fit forward neural network, multi layer perception from scratch. And now we have all of the different elements to it. We have forward propagation, we have back propagation, we have gradient descent, we know how we can train it uh everything like it's super modular because you can put like as many uh layers uh in the network as you want and you can specify as many like neurons as you want like, so that's like also like really nice. And so yeah, I think like we should just like congratulate ourselves because I guess like we know way more than most people out there uh who are also like machine learning practitioners because like we know how to build a neural network, a simple neural network from scratch",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3673s",
        "start_time": "3673.159"
    },
    {
        "id": "b4037eae",
        "text": "we have back propagation, we have gradient descent, we know how we can train it uh everything like it's super modular because you can put like as many uh layers uh in the network as you want and you can specify as many like neurons as you want like, so that's like also like really nice. And so yeah, I think like we should just like congratulate ourselves because I guess like we know way more than most people out there uh who are also like machine learning practitioners because like we know how to build a neural network, a simple neural network from scratch good. So this was it for this very very long video. I hope you enjoyed it. And uh if you did please uh subscribe and hit the notification bell. So you'll just like get new videos when they are uploaded and then um for the next time, what we'll do is we're gonna basically build something very similar to this with tensorflow. And you'll see",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3690s",
        "start_time": "3690.8"
    },
    {
        "id": "375fca4c",
        "text": "out there uh who are also like machine learning practitioners because like we know how to build a neural network, a simple neural network from scratch good. So this was it for this very very long video. I hope you enjoyed it. And uh if you did please uh subscribe and hit the notification bell. So you'll just like get new videos when they are uploaded and then um for the next time, what we'll do is we're gonna basically build something very similar to this with tensorflow. And you'll see that all the time that we spent like doing this. It's gonna take, I don't know, like probably 1/10 like of the, of the time and the number of like uh uh lines of code for doing that. And so yeah, we'll get into tensor flow and carrots and we'll build a simple M LP from scratch. So stay tuned and like this video and I'll see you next time. Cheers.",
        "video": "8- TRAINING A NEURAL NETWORK: Implementing backpropagation and gradient descent from scratch",
        "playlist": "Audio Deep Learning with Python",
        "youtube_video_id": "Z97XGNUUx9o",
        "youtube_link": "https://www.youtube.com/watch?v=Z97XGNUUx9o&t=3716s",
        "start_time": "3716.199"
    }
]