{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8456b5b6-185b-440b-ab98-1822aac2fe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dataset_path = \"../app/data/dataset.json\"\n",
    "with open(dataset_path, 'rt') as file:\n",
    "    documents = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e20f851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'd8917aa5',\n",
       " 'text': \"Hi, everybody and welcome to a new exciting video in the audio signal processing for machine learning series. This time, we'll look into a very important audio feature. In other words, Mal frequency seal coefficient or if we use their acronym MF CCS. But before we get started with this super cool topic, I want to remind you about the sound of the Ice L community. So if you sign up there, you can get feedback, share projects and share ideas with a community of people who are interested in A I audio A I music and audio signal processing. So I really invite you to check this community out and I'll leave you the link and the sign up link to the Slack workspace in the description box below. Now let's move on to the cool stuff. But before we get to M I want just like to remind you about what we did in the previous couple of videos and we focused on male spectrograms. Now male spectrograms are going to be like an important building block to understanding MF CCS. So if you are really not that familiar with that, I highly suggest you to go check out my previous couple of videos on male spectrograms. OK? But now let's get started with MFC\",\n",
       " 'video': 'Mel-Frequency Cepstral Coefficients Explained Easily',\n",
       " 'playlist': 'Audio Signal Processing for ML',\n",
       " 'youtube_video_id': '4_SH2nfbQZ8',\n",
       " 'youtube_link': 'https://www.youtube.com/watch?v=4_SH2nfbQZ8&t=0s',\n",
       " 'start_time': '0.0'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5833e987-21f5-4788-8609-d32410bc7b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e482cd0-0202-4a89-854d-90b50c75e520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a35364d6a02e412d8a36e1957cf977f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "402e396e26254a55ab65db7c3ce13859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d939cc3f34a4a2eb4283dc1728772bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.73k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed89a6d6f86463b8e803266db0bed65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "427c9d134b6d431396eb598302ef3dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc528380bc954399a25610861c7b2e0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f471ca499f401798d93b4d2718e9ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc95a43841b4f3ea2b7f178be98f046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e5678077a94d259830a383beed70a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d80d9e194084f339b570c6bd8c63c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a8b7b043664a2c9bd3c6a30f17564f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model_name = 'multi-qa-MiniLM-L6-cos-v1'\n",
    "model_name = \"paraphrase-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "620ed5a1-cc06-40a3-8627-891aed525cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es_client = Elasticsearch('http://localhost:9200') \n",
    "ES_INDEX = \"youtube-questions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91721a90-96d6-4ef9-8baf-a3d42c4b03e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82a78984-1440-4195-9513-106109013fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How to extract frequency from audio file?\"\n",
    "playlist = \"Audio Signal Processing for ML\"\n",
    "\n",
    "v_q = model.encode(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "735eb433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_knn(field, query_vector, playlist, num_results=5):\n",
    "    \n",
    "    knn = {\n",
    "        \"field\": field,     # options: \"text_vector\", \"video_vector\", \"text_video_vector\"\n",
    "        \"query_vector\": query_vector,\n",
    "        \"k\": num_results,\n",
    "        \"num_candidates\": 10000, \n",
    "        \"filter\": {\n",
    "            \"term\": {\n",
    "                \"playlist\": playlist\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    search_query = {\n",
    "        \"knn\": knn,\n",
    "        \"_source\": [\"id\", \"text\", \"video\", \"playlist\", \"youtube_link\"]\n",
    "    }\n",
    "    \n",
    "    response = es_client.search(index=ES_INDEX, body=search_query)\n",
    "\n",
    "    result_docs = []\n",
    "    if 'hits' in response and 'hits' in response['hits']:\n",
    "        for hit in response['hits']['hits']:\n",
    "            result_docs.append(hit['_source'])\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc09b90a-a88b-4678-a613-eb68e16136d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_vector_knn(q):\n",
    "    question = q['questions']\n",
    "    playlist = q['playlist']\n",
    "\n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return elastic_search_knn('video_vector', v_q, playlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d53d3beb-d699-46c8-bc85-953afc4ef48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_dataset_path = \"../app/data/ground_truth_dataset.json\"\n",
    "with open(ground_truth_dataset_path, 'rt') as file:\n",
    "    ground_truth = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0deced29-bae5-4b6c-b2b8-53ce46b4f8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'd8917aa5',\n",
       " 'playlist': 'Audio Signal Processing for ML',\n",
       " 'questions': 'What is the main focus of the video in the audio signal processing for machine learning series?'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8959c9ff-5bbe-4729-8fa3-cdc51ed10f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "842255b5-18f2-4102-9689-a5835e0a621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f11baaff-43d9-4b8c-a896-561b86e85743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['id']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1d3530e-1406-49dd-bba9-914f6a39d7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaddb99c1485420e838058e8d6764aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36490 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.01833379007947383, 'mrr': 0.008511921074266897}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, video_vector_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e87f0987-02e9-4e2c-a091-14a75c9ce58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_vector_knn(q):\n",
    "    question = q['questions']\n",
    "    playlist = q['playlist']\n",
    "\n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return elastic_search_knn('text_vector', v_q, playlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d676bd5e-4abc-4799-bb37-c1a86b3b9872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96fc1aef320a4d1d84381b6842ac992b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36490 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.4104960263085777, 'mrr': 0.2556312231661629}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, text_vector_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13a47c3e-036a-4212-912c-a61de0daf6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb00b76af9b4aa38c19bf6ba688ca58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36490 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.37155385036996436, 'mrr': 0.2239919612679154}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_video_vector_knn(q):\n",
    "    question = q['questions']\n",
    "    playlist = q['playlist']\n",
    "\n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return elastic_search_knn('text_video_vector', v_q, playlist)\n",
    "\n",
    "evaluate(ground_truth, text_video_vector_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20f4d5f5-617d-4e89-8cc1-4acaed270be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_knn_combined(vector, playlist):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": [\n",
    "                    {\n",
    "                        \"script_score\": {\n",
    "                            \"query\": {\n",
    "                                \"term\": {\n",
    "                                    \"playlist\": playlist\n",
    "                                }\n",
    "                            },\n",
    "                            \"script\": {\n",
    "                                \"source\": \"\"\"\n",
    "                                    cosineSimilarity(params.query_vector, 'video_vector') + \n",
    "                                    cosineSimilarity(params.query_vector, 'text_vector') + \n",
    "                                    cosineSimilarity(params.query_vector, 'text_video_vector') + \n",
    "                                    1\n",
    "                                \"\"\",\n",
    "                                \"params\": {\n",
    "                                    \"query_vector\": vector\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"playlist\": playlist\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"_source\": [\"id\", \"text\", \"video\", \"playlist\", \"youtube_link\"]\n",
    "    \n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(\n",
    "        index=ES_INDEX,\n",
    "        body=search_query\n",
    "    )\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in es_results['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ba72a59-7d0e-4d61-90c4-008e6341f7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5294f671f2f14c2c9477091f8f1cdd1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36490 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.3520416552480132, 'mrr': 0.21325888371242185}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vector_combined_knn(q):\n",
    "    question = q['questions']\n",
    "    playlist = q['playlist']\n",
    "\n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return elastic_search_knn_combined(v_q, playlist)\n",
    "\n",
    "evaluate(ground_truth, vector_combined_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dc4461",
   "metadata": {},
   "source": [
    "## The best approach for Vector searching is to use Text_Vector search.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
